[
  {
    "objectID": "week1_1b.html",
    "href": "week1_1b.html",
    "title": "R Packages",
    "section": "",
    "text": "One of the main reasons to be excited about R is the package library system. In R, packages are like apps. R packages extend the functionality of base R by providing additional functions, data, and documentation. They are written by a worldwide community of R users and can be downloaded freely without much hassle (compared to many other package libraries). For example, we will often use the ggplot2 package for plotting and visualizing data and the psych package for describing data numerically.\nTo install R packages you can use the install.packages() function directly in the console as follows:\n\ninstall.packages(\"ggplot2\")\n\nor you can do so from the Packages tab of the Files pane in RStudio using the following steps:\n\nClick on the “Packages” tab.\nClick on “Install” next to Update.\nType the name of the package under “Packages (separate multiple with space or comma):” In this case, type ggplot2.\nClick “Install.”\n\n\n\n\nInstall packages using RStudio",
    "crumbs": [
      "Introduction to R",
      "R Packages"
    ]
  },
  {
    "objectID": "week1_1b.html#installing-r-packages",
    "href": "week1_1b.html#installing-r-packages",
    "title": "R Packages",
    "section": "",
    "text": "One of the main reasons to be excited about R is the package library system. In R, packages are like apps. R packages extend the functionality of base R by providing additional functions, data, and documentation. They are written by a worldwide community of R users and can be downloaded freely without much hassle (compared to many other package libraries). For example, we will often use the ggplot2 package for plotting and visualizing data and the psych package for describing data numerically.\nTo install R packages you can use the install.packages() function directly in the console as follows:\n\ninstall.packages(\"ggplot2\")\n\nor you can do so from the Packages tab of the Files pane in RStudio using the following steps:\n\nClick on the “Packages” tab.\nClick on “Install” next to Update.\nType the name of the package under “Packages (separate multiple with space or comma):” In this case, type ggplot2.\nClick “Install.”\n\n\n\n\nInstall packages using RStudio",
    "crumbs": [
      "Introduction to R",
      "R Packages"
    ]
  },
  {
    "objectID": "week1_1b.html#using-r-packages",
    "href": "week1_1b.html#using-r-packages",
    "title": "R Packages",
    "section": "Using R Packages",
    "text": "Using R Packages\nOnce a package is installed you can load it into your environment using the library() function. Once loaded you have access to all the R functions supplied by that package.\n\nlibrary(\"ggplot2\")",
    "crumbs": [
      "Introduction to R",
      "R Packages"
    ]
  },
  {
    "objectID": "week1_1b.html#finding-useful-r-packages",
    "href": "week1_1b.html#finding-useful-r-packages",
    "title": "R Packages",
    "section": "Finding Useful R Packages",
    "text": "Finding Useful R Packages\nThere are many ways to find useful R packages on the internet simply by googling the type of data or analysis you are interested in. Another way is to look at the CRAN Task Views. For example, there is an interesting Task View for Machine Learning that contains many relevant packages you might be interested in using. Some class members expressed interest in F1 racing. In the Sports Analytics Task View there is a f1dataR package that provides historical data from the beginning of Formula 1.",
    "crumbs": [
      "Introduction to R",
      "R Packages"
    ]
  },
  {
    "objectID": "week2_2b.html#examples-items-instances-or-cases",
    "href": "week2_2b.html#examples-items-instances-or-cases",
    "title": "Terminology Notes",
    "section": "Examples, Items, Instances or Cases",
    "text": "Examples, Items, Instances or Cases\n\nDefinition: Individual data points used for learning or evaluation.\n\nExample: Each participant in a study, with their responses to a cognitive task or survey questionnaire.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Terminology Notes"
    ]
  },
  {
    "objectID": "week2_2b.html#features",
    "href": "week2_2b.html#features",
    "title": "Terminology Notes",
    "section": "Features",
    "text": "Features\n\nDefinition: Attributes or variables associated with each example, often represented as a vector.\n\nExample: Participant age, gender, response times, scores on survey items, or physiological measures (e.g., heart rate, skin conductance).",
    "crumbs": [
      "Introduction to Machine Learning",
      "Terminology Notes"
    ]
  },
  {
    "objectID": "week2_2b.html#labels",
    "href": "week2_2b.html#labels",
    "title": "Terminology Notes",
    "section": "Labels",
    "text": "Labels\n\nDefinition: The outcome, value, or category assigned to each example.\n\nExample:\n\nClassification: Diagnosed vs. non-diagnosed for depression.\n\nRegression: Continuous depression score on a scale from 0–30.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Terminology Notes"
    ]
  },
  {
    "objectID": "week2_2b.html#training-sample",
    "href": "week2_2b.html#training-sample",
    "title": "Terminology Notes",
    "section": "Training Sample",
    "text": "Training Sample\n\nDefinition: The subset of examples used to train the learning algorithm.\n\nExample: 100 participants’ data with known depression scores used to train a predictive model.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Terminology Notes"
    ]
  },
  {
    "objectID": "week2_2b.html#validation-sample",
    "href": "week2_2b.html#validation-sample",
    "title": "Terminology Notes",
    "section": "Validation Sample",
    "text": "Validation Sample\n\nDefinition: Examples used to tune algorithm parameters (e.g., regularization strength, number of neurons in a network).\n\nExample: 30 participants’ data used to select the optimal model settings or tuning parameters before final evaluation.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Terminology Notes"
    ]
  },
  {
    "objectID": "week2_2b.html#test-sample",
    "href": "week2_2b.html#test-sample",
    "title": "Terminology Notes",
    "section": "Test Sample",
    "text": "Test Sample\n\nDefinition: Examples used to evaluate model performance, separate from training and validation. Examples used to evaluate the performance of a learning algorithm. The test sample is not made available in the learning stage.\nExample: 50 new participants whose depression scores the model predicts; predicted scores are compared to actual scores to assess accuracy.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Terminology Notes"
    ]
  },
  {
    "objectID": "week2_2b.html#loss-function",
    "href": "week2_2b.html#loss-function",
    "title": "Terminology Notes",
    "section": "Loss Function",
    "text": "Loss Function\n\nDefinition: A function that measures the difference between predicted labels and true labels.\n\nExample:\nRegression: Squared loss: L(y, y′) = (y′ − y)², e.g., predicted vs. actual depression score.\n\nClassification: Zero-one loss: L(y, y′) = 1 if prediction ≠ true label, e.g., predicted diagnosis vs. actual diagnosis.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Terminology Notes"
    ]
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "PSYC559: Applied Machine Learning in Psychology",
    "section": "",
    "text": "https://zackfisher.github.io/PSYC559/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSC559: Applied Machine Learning in Psychology",
    "section": "",
    "text": "Welcome to the PSC559: Applied Machine Learning in Psychology!\nAs the class progresses I will update this front matter with a general course overview and important announcements.\nIf you find errors or typos in any of these materials please let me know."
  },
  {
    "objectID": "week2_3.html",
    "href": "week2_3.html",
    "title": "Data Splitting",
    "section": "",
    "text": "Data splitting (e.g., dividing data into training, validation, and test samples) is crucial because it protects us from fooling ourselves about how well a model actually performs.\n\n\n\nThe subset of examples used to train the learning algorithm. Here we typically estimate the model’s parameters in the training sample.\nFor example, if we have data from 150 participants, we might keep data from 100 participants (with known depression scores) to train a predictive model.\nNotes: Spending too much in training won’t allow us to get a good assessment of predictive performance. We may find a model that fits the training data very well, but is not generalizable (overfitting).\n\n\n\n\n\nSamples used to tune algorithm hyperparameters (e.g., regularization strength, number of neurons in a network).\nFor example, from our 100 individuals in the training sample, we may split the training data into 4 groups of 25 participants. Each of these will be a validation sample, and allow us to select the optimal model settings or tuning parameters before our final evaluation.\n\n\n\n\n\nThe test Sample used to evaluate model performance, separate from training and validation. The test sample is not made available in the learning stage. Sometimes too much spent in testing won’t allow us to get a good assessment of model parameters.\nFor example, for those 50 participants we never looked out may be our test data. The model can now be used to predict depression scores ; predicted scores for the individuals in the test sample. Here we can now compare actual scores to assess accuracy.\n\n\n\n\nhttps://www.statology.org/validation-set-vs-test-set/\nIn groups of 3–4, discuss:",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week2_3.html#parameters-vs.-hyperparameters",
    "href": "week2_3.html#parameters-vs.-hyperparameters",
    "title": "Data Splitting",
    "section": "Parameters vs. Hyperparameters",
    "text": "Parameters vs. Hyperparameters\n\nParameters are values learned automatically (or estimated) from the training data. The model parameters are often the thing we are interested in estimating in a given algorithm.\nFor example. the slope of the line in a simple linear regression prediction problem relating amount of treatment (feature) to depression score (target).\nHyperparameters are set before training begins, and control how the learning process works. The selection of hyperparameters is often critical to model performance, as in procedures like k-folds cross-validation, playing a critical role in how the model generalizes.\nFor example, the the number of clusters used to partition the data",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week2_3.html#role-of-parameters-in-data-splitting",
    "href": "week2_3.html#role-of-parameters-in-data-splitting",
    "title": "Data Splitting",
    "section": "Role of Parameters in Data Splitting",
    "text": "Role of Parameters in Data Splitting\nWhen we split data, each portion plays a distinct role:\n\nTraining set → Fit the model parameters.\n\nValidation set → Used to compare different hyperparameter choices.\n\nTest set → Used only once, at the very end, to estimate generalization performance.\n\nImportant note: Hyperparameters should be tuned using the validation set, not the test set. If we adjust hyperparameters based on the test set, we are indirectly training on it and lose the ability to measure real-world performance.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week2_3.html#example-k-means-clustering",
    "href": "week2_3.html#example-k-means-clustering",
    "title": "Data Splitting",
    "section": "Example: k-Means Clustering",
    "text": "Example: k-Means Clustering\n\nParameters (learned from the data)\n\nCluster centroids: the coordinates of the cluster centers.\n\nThese are calculated by the algorithm during training and adjusted iteratively until convergence.\n\nYou do not set them manually — the algorithm figures them out.\n\n\n\nHyperparameters (set before training)\n\nNumber of clusters (k): chosen by the user before running the algorithm.\n\nInitialization method (e.g., random, k-means++).\n\nMaximum number of iterations allowed.\n\nThese control how the algorithm runs, but are not learned from the data itself.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week2_3.html#prevents-overfitting-to-the-training-data",
    "href": "week2_3.html#prevents-overfitting-to-the-training-data",
    "title": "Data Splitting",
    "section": "Prevents Overfitting to the Training Data",
    "text": "Prevents Overfitting to the Training Data\n\nWhen a model is trained, it adapts to patterns in the training set.\n\nIf we only check performance on that same data, we might think the model is excellent — but it may just be memorizing instead of generalizing.\n\nA separate test set lets us see how the model behaves on new, unseen data.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week2_3.html#simulates-real-world-performance",
    "href": "week2_3.html#simulates-real-world-performance",
    "title": "Data Splitting",
    "section": "Simulates Real-World Performance",
    "text": "Simulates Real-World Performance\n\nIn real life, the model will be applied to data it hasn’t seen before.\n\nBy holding out a test set, we simulate that scenario, giving us a better sense of expected performance in practice.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week2_3.html#helps-with-model-selection-tuning",
    "href": "week2_3.html#helps-with-model-selection-tuning",
    "title": "Data Splitting",
    "section": "Helps with Model Selection & Tuning",
    "text": "Helps with Model Selection & Tuning\n\nA validation set (or cross-validation) is used to choose hyperparameters (like tree depth, learning rate, regularization strength).\n\nIf we tuned on the test set, we’d essentially be “leaking” information, and performance estimates would be biased upward.\n\nProper splitting ensures that the test set remains untouched until the very end.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week2_3.html#detects-data-leakage",
    "href": "week2_3.html#detects-data-leakage",
    "title": "Data Splitting",
    "section": "Detects Data Leakage",
    "text": "Detects Data Leakage\n\nSometimes information from the future or from labels sneaks into the features.\n\nIf this happens, the model might look perfect on the training set but fail on a clean split.\n\nData splitting may not actually help data leakage though. When might it help and when might it not?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week2_3.html#provides-a-fair-benchmark",
    "href": "week2_3.html#provides-a-fair-benchmark",
    "title": "Data Splitting",
    "section": "Provides a Fair Benchmark",
    "text": "Provides a Fair Benchmark\n\nIn research and industry, different models need to be compared on a common, untouched test set.\n\nWithout splitting, comparisons aren’t meaningful, since each model might overfit differently.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Data Splitting"
    ]
  },
  {
    "objectID": "week1_4.html",
    "href": "week1_4.html",
    "title": "Describing Data Visually",
    "section": "",
    "text": "This section will briefly introduce you to visualizing data using the ggplot2 package. R has a number of systems for making graphs but ggplot2 is by far the most developed option. ggplot2 implements the grammar of graphics, and if you’d like to learn more about the motivation for this work take a look at The Layered Grammar of Graphics.\n\n\nOnce we know the data has been read into R we can look at how R understands the data file using the structure function str()\nLet’s install ggplot2, and then load the package.\n\ninstall.packages(\"ggplot2\") # install the package\n\n\nlibrary(\"ggplot2\") # load the library\n\n\n\n\nggplot2 contains a dataset titled mpg that contains observations collected by the US Environmental Protection Agency on 38 models of car. Let’s look at the dataset using the describe() function.\n\nlibrary(\"psych\") # load the library\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\ndescribe(mpg)\n\n              vars   n    mean    sd median trimmed   mad    min  max range\nmanufacturer*    1 234    7.76  5.13    6.0    7.68  5.93    1.0   15  14.0\nmodel*           2 234   19.09 11.15   18.5   18.98 14.08    1.0   38  37.0\ndispl            3 234    3.47  1.29    3.3    3.39  1.33    1.6    7   5.4\nyear             4 234 2003.50  4.51 2003.5 2003.50  6.67 1999.0 2008   9.0\ncyl              5 234    5.89  1.61    6.0    5.86  2.97    4.0    8   4.0\ntrans*           6 234    5.65  2.88    4.0    5.53  1.48    1.0   10   9.0\ndrv*             7 234    1.67  0.66    2.0    1.59  1.48    1.0    3   2.0\ncty              8 234   16.86  4.26   17.0   16.61  4.45    9.0   35  26.0\nhwy              9 234   23.44  5.95   24.0   23.23  7.41   12.0   44  32.0\nfl*             10 234    4.63  0.70    5.0    4.77  0.00    1.0    5   4.0\nclass*          11 234    4.59  1.99    5.0    4.64  2.97    1.0    7   6.0\n               skew kurtosis   se\nmanufacturer*  0.21    -1.63 0.34\nmodel*         0.11    -1.23 0.73\ndispl          0.44    -0.91 0.08\nyear           0.00    -2.01 0.29\ncyl            0.11    -1.46 0.11\ntrans*         0.29    -1.65 0.19\ndrv*           0.48    -0.76 0.04\ncty            0.79     1.43 0.28\nhwy            0.36     0.14 0.39\nfl*           -2.25     5.76 0.05\nclass*        -0.14    -1.52 0.13\n\n\n\n\n\nLet’s take a look at two variables in the mpg dataset.\n\ndispl, a car’s engine size, in litres.\nhwy, a car’s fuel efficiency on the highway, in miles per gallon (mpg). A car with a low fuel efficiency consumes more fuel than a car with a high fuel efficiency when they travel the same distance.\n\nTo plot mpg, run this code to put displ on the x-axis and hwy on the y-axis:\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\n\n\n\n\n\n\n\n\nWe can also convey information about our data by mapping the aesthetics in our plots to the variables in our dataset. For example, we can map the colors of the data points to the class variable to reveal the class of each car.\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = class))\n\n\n\n\n\n\n\n\nLastly, we can use facets to split a larger plot into subplots. This can be helpful when we want to break apart our data based on a categorical variable.\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)",
    "crumbs": [
      "Introduction to R",
      "Describing Data Visually"
    ]
  },
  {
    "objectID": "week1_4.html#data-visualization",
    "href": "week1_4.html#data-visualization",
    "title": "Describing Data Visually",
    "section": "",
    "text": "This section will briefly introduce you to visualizing data using the ggplot2 package. R has a number of systems for making graphs but ggplot2 is by far the most developed option. ggplot2 implements the grammar of graphics, and if you’d like to learn more about the motivation for this work take a look at The Layered Grammar of Graphics.\n\n\nOnce we know the data has been read into R we can look at how R understands the data file using the structure function str()\nLet’s install ggplot2, and then load the package.\n\ninstall.packages(\"ggplot2\") # install the package\n\n\nlibrary(\"ggplot2\") # load the library\n\n\n\n\nggplot2 contains a dataset titled mpg that contains observations collected by the US Environmental Protection Agency on 38 models of car. Let’s look at the dataset using the describe() function.\n\nlibrary(\"psych\") # load the library\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\ndescribe(mpg)\n\n              vars   n    mean    sd median trimmed   mad    min  max range\nmanufacturer*    1 234    7.76  5.13    6.0    7.68  5.93    1.0   15  14.0\nmodel*           2 234   19.09 11.15   18.5   18.98 14.08    1.0   38  37.0\ndispl            3 234    3.47  1.29    3.3    3.39  1.33    1.6    7   5.4\nyear             4 234 2003.50  4.51 2003.5 2003.50  6.67 1999.0 2008   9.0\ncyl              5 234    5.89  1.61    6.0    5.86  2.97    4.0    8   4.0\ntrans*           6 234    5.65  2.88    4.0    5.53  1.48    1.0   10   9.0\ndrv*             7 234    1.67  0.66    2.0    1.59  1.48    1.0    3   2.0\ncty              8 234   16.86  4.26   17.0   16.61  4.45    9.0   35  26.0\nhwy              9 234   23.44  5.95   24.0   23.23  7.41   12.0   44  32.0\nfl*             10 234    4.63  0.70    5.0    4.77  0.00    1.0    5   4.0\nclass*          11 234    4.59  1.99    5.0    4.64  2.97    1.0    7   6.0\n               skew kurtosis   se\nmanufacturer*  0.21    -1.63 0.34\nmodel*         0.11    -1.23 0.73\ndispl          0.44    -0.91 0.08\nyear           0.00    -2.01 0.29\ncyl            0.11    -1.46 0.11\ntrans*         0.29    -1.65 0.19\ndrv*           0.48    -0.76 0.04\ncty            0.79     1.43 0.28\nhwy            0.36     0.14 0.39\nfl*           -2.25     5.76 0.05\nclass*        -0.14    -1.52 0.13\n\n\n\n\n\nLet’s take a look at two variables in the mpg dataset.\n\ndispl, a car’s engine size, in litres.\nhwy, a car’s fuel efficiency on the highway, in miles per gallon (mpg). A car with a low fuel efficiency consumes more fuel than a car with a high fuel efficiency when they travel the same distance.\n\nTo plot mpg, run this code to put displ on the x-axis and hwy on the y-axis:\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\n\n\n\n\n\n\n\n\nWe can also convey information about our data by mapping the aesthetics in our plots to the variables in our dataset. For example, we can map the colors of the data points to the class variable to reveal the class of each car.\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = class))\n\n\n\n\n\n\n\n\nLastly, we can use facets to split a larger plot into subplots. This can be helpful when we want to break apart our data based on a categorical variable.\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)",
    "crumbs": [
      "Introduction to R",
      "Describing Data Visually"
    ]
  },
  {
    "objectID": "week1_2.html",
    "href": "week1_2.html",
    "title": "Reading in Data",
    "section": "",
    "text": "One of the most important initial tasks you’ll face in R is reading in data. Let’s walk through some basics.\nBy reading in data we are generally refering to the process of importing data from a local directory on your computer, or from the web, into R. When we read a data file into R, we often read it in as a tabularobject where columns representing variables and rows representing cases. This is not always the case but covers the most basic use case.\n\n\n\nExample of tabular data\n\n\nMany different data file formats can be read into R as data frames, such as .csv (comma separated values), .xlsx (Excel workbook), .txt (text), .sas7bdat (SAS), and .sav (SPSS) can be read into R. We will mostly focus on the .csv case in this class.\n\n\nOne of the trickiest parts of loading data from your hard drive into R is knowing how to locate it. Depending on whether you are using a Mac or Windows machine you can read in .csv files directly if you know the path. For example, I can load a .csv file into R and save it as a data frame labeled df as follows:\n\ndf &lt;- read.csv(\"/Users/zacharyfisher/Dropbox/Macbook/UNC/Teaching/Courses/PSYC559/PSYC559-Site/data/ifood_df.csv\")\n\nOnce the .csv file is loaded I can look at it using the View() function\n\nView(df)\n\nor simple examine the first few cases using head()\n\nhead(df)\n\n  Income Kidhome Teenhome Recency MntWines MntFruits MntMeatProducts\n1  58138       0        0      58      635        88             546\n2  46344       1        1      38       11         1               6\n3  71613       0        0      26      426        49             127\n4  26646       1        0      26       11         4              20\n5  58293       1        0      94      173        43             118\n6  62513       0        1      16      520        42              98\n  MntFishProducts MntSweetProducts MntGoldProds NumDealsPurchases\n1             172               88           88                 3\n2               2                1            6                 2\n3             111               21           42                 1\n4              10                3            5                 2\n5              46               27           15                 5\n6               0               42           14                 2\n  NumWebPurchases NumCatalogPurchases NumStorePurchases NumWebVisitsMonth\n1               8                  10                 4                 7\n2               1                   1                 2                 5\n3               8                   2                10                 4\n4               2                   0                 4                 6\n5               5                   3                 6                 5\n6               6                   4                10                 6\n  AcceptedCmp3 AcceptedCmp4 AcceptedCmp5 AcceptedCmp1 AcceptedCmp2 Complain\n1            0            0            0            0            0        0\n2            0            0            0            0            0        0\n3            0            0            0            0            0        0\n4            0            0            0            0            0        0\n5            0            0            0            0            0        0\n6            0            0            0            0            0        0\n  Z_CostContact Z_Revenue Response Age Customer_Days marital_Divorced\n1             3        11        1  63          2822                0\n2             3        11        0  66          2272                0\n3             3        11        0  55          2471                0\n4             3        11        0  36          2298                0\n5             3        11        0  39          2320                0\n6             3        11        0  53          2452                0\n  marital_Married marital_Single marital_Together marital_Widow\n1               0              1                0             0\n2               0              1                0             0\n3               0              0                1             0\n4               0              0                1             0\n5               1              0                0             0\n6               0              0                1             0\n  education_2n.Cycle education_Basic education_Graduation education_Master\n1                  0               0                    1                0\n2                  0               0                    1                0\n3                  0               0                    1                0\n4                  0               0                    1                0\n5                  0               0                    0                0\n6                  0               0                    0                1\n  education_PhD MntTotal MntRegularProds AcceptedCmpOverall\n1             0     1529            1441                  0\n2             0       21              15                  0\n3             0      734             692                  0\n4             0       48              43                  0\n5             1      407             392                  0\n6             0      702             688                  0\n\n\n\n\n\nAnother way to load data is to set the working directory to the folder where the data is located. This can be helpful if you are having trouble finding the path to the data. From RStudio, use the menu to change your working directory under Session &gt; Set Working Directory &gt; Choose Directory. Then set the working directory to the folder where you have stored your data. Conveniently, you will also now see a path to the data in your R console you can use to Copy-Paste a path. Now you can simply use the filename of the .csv file to read in the data. See the example below.\n\n\n\nSet the working directory in RStudio.\n\n\n\nsetwd(\"/Users/zacharyfisher/Dropbox/Macbook/UNC/Teaching/Courses/PSYC559/PSYC559-Site/data\")\ndf &lt;- read.csv(\"ifood_df.csv\")\n\nIn addition to setwd() you can also find what your current working directory is using the getwd() command.",
    "crumbs": [
      "Introduction to R",
      "Reading in Data"
    ]
  },
  {
    "objectID": "week1_2.html#loading-data",
    "href": "week1_2.html#loading-data",
    "title": "Reading in Data",
    "section": "",
    "text": "One of the most important initial tasks you’ll face in R is reading in data. Let’s walk through some basics.\nBy reading in data we are generally refering to the process of importing data from a local directory on your computer, or from the web, into R. When we read a data file into R, we often read it in as a tabularobject where columns representing variables and rows representing cases. This is not always the case but covers the most basic use case.\n\n\n\nExample of tabular data\n\n\nMany different data file formats can be read into R as data frames, such as .csv (comma separated values), .xlsx (Excel workbook), .txt (text), .sas7bdat (SAS), and .sav (SPSS) can be read into R. We will mostly focus on the .csv case in this class.\n\n\nOne of the trickiest parts of loading data from your hard drive into R is knowing how to locate it. Depending on whether you are using a Mac or Windows machine you can read in .csv files directly if you know the path. For example, I can load a .csv file into R and save it as a data frame labeled df as follows:\n\ndf &lt;- read.csv(\"/Users/zacharyfisher/Dropbox/Macbook/UNC/Teaching/Courses/PSYC559/PSYC559-Site/data/ifood_df.csv\")\n\nOnce the .csv file is loaded I can look at it using the View() function\n\nView(df)\n\nor simple examine the first few cases using head()\n\nhead(df)\n\n  Income Kidhome Teenhome Recency MntWines MntFruits MntMeatProducts\n1  58138       0        0      58      635        88             546\n2  46344       1        1      38       11         1               6\n3  71613       0        0      26      426        49             127\n4  26646       1        0      26       11         4              20\n5  58293       1        0      94      173        43             118\n6  62513       0        1      16      520        42              98\n  MntFishProducts MntSweetProducts MntGoldProds NumDealsPurchases\n1             172               88           88                 3\n2               2                1            6                 2\n3             111               21           42                 1\n4              10                3            5                 2\n5              46               27           15                 5\n6               0               42           14                 2\n  NumWebPurchases NumCatalogPurchases NumStorePurchases NumWebVisitsMonth\n1               8                  10                 4                 7\n2               1                   1                 2                 5\n3               8                   2                10                 4\n4               2                   0                 4                 6\n5               5                   3                 6                 5\n6               6                   4                10                 6\n  AcceptedCmp3 AcceptedCmp4 AcceptedCmp5 AcceptedCmp1 AcceptedCmp2 Complain\n1            0            0            0            0            0        0\n2            0            0            0            0            0        0\n3            0            0            0            0            0        0\n4            0            0            0            0            0        0\n5            0            0            0            0            0        0\n6            0            0            0            0            0        0\n  Z_CostContact Z_Revenue Response Age Customer_Days marital_Divorced\n1             3        11        1  63          2822                0\n2             3        11        0  66          2272                0\n3             3        11        0  55          2471                0\n4             3        11        0  36          2298                0\n5             3        11        0  39          2320                0\n6             3        11        0  53          2452                0\n  marital_Married marital_Single marital_Together marital_Widow\n1               0              1                0             0\n2               0              1                0             0\n3               0              0                1             0\n4               0              0                1             0\n5               1              0                0             0\n6               0              0                1             0\n  education_2n.Cycle education_Basic education_Graduation education_Master\n1                  0               0                    1                0\n2                  0               0                    1                0\n3                  0               0                    1                0\n4                  0               0                    1                0\n5                  0               0                    0                0\n6                  0               0                    0                1\n  education_PhD MntTotal MntRegularProds AcceptedCmpOverall\n1             0     1529            1441                  0\n2             0       21              15                  0\n3             0      734             692                  0\n4             0       48              43                  0\n5             1      407             392                  0\n6             0      702             688                  0\n\n\n\n\n\nAnother way to load data is to set the working directory to the folder where the data is located. This can be helpful if you are having trouble finding the path to the data. From RStudio, use the menu to change your working directory under Session &gt; Set Working Directory &gt; Choose Directory. Then set the working directory to the folder where you have stored your data. Conveniently, you will also now see a path to the data in your R console you can use to Copy-Paste a path. Now you can simply use the filename of the .csv file to read in the data. See the example below.\n\n\n\nSet the working directory in RStudio.\n\n\n\nsetwd(\"/Users/zacharyfisher/Dropbox/Macbook/UNC/Teaching/Courses/PSYC559/PSYC559-Site/data\")\ndf &lt;- read.csv(\"ifood_df.csv\")\n\nIn addition to setwd() you can also find what your current working directory is using the getwd() command.",
    "crumbs": [
      "Introduction to R",
      "Reading in Data"
    ]
  },
  {
    "objectID": "week1_3.html",
    "href": "week1_3.html",
    "title": "Describing Data Numerically",
    "section": "",
    "text": "Once you have read in a data frame it can be useful to know how the variables are understood by R. For example, let’s look at some Kaggle Marketing Analytics Data. You can download the raw data here.\n\n\n\nData dictionary for marketing data\n\n\n\n\nLet’s read in the data using the read.csv() function.\n\nsetwd(\"/Users/zacharyfisher/Dropbox/Macbook/UNC/Teaching/Courses/PSYC559/PSYC559-Site/data\")\ndf &lt;- read.csv(\"ifood_df.csv\")\n\n\n\n\nOnce we know the data has been read into R we can look at how R understands the data file using the structure function str()\n\nstr(df)\n\n'data.frame':   2205 obs. of  39 variables:\n $ Income              : num  58138 46344 71613 26646 58293 ...\n $ Kidhome             : int  0 1 0 1 1 0 0 1 1 1 ...\n $ Teenhome            : int  0 1 0 0 0 1 1 0 0 1 ...\n $ Recency             : int  58 38 26 26 94 16 34 32 19 68 ...\n $ MntWines            : int  635 11 426 11 173 520 235 76 14 28 ...\n $ MntFruits           : int  88 1 49 4 43 42 65 10 0 0 ...\n $ MntMeatProducts     : int  546 6 127 20 118 98 164 56 24 6 ...\n $ MntFishProducts     : int  172 2 111 10 46 0 50 3 3 1 ...\n $ MntSweetProducts    : int  88 1 21 3 27 42 49 1 3 1 ...\n $ MntGoldProds        : int  88 6 42 5 15 14 27 23 2 13 ...\n $ NumDealsPurchases   : int  3 2 1 2 5 2 4 2 1 1 ...\n $ NumWebPurchases     : int  8 1 8 2 5 6 7 4 3 1 ...\n $ NumCatalogPurchases : int  10 1 2 0 3 4 3 0 0 0 ...\n $ NumStorePurchases   : int  4 2 10 4 6 10 7 4 2 0 ...\n $ NumWebVisitsMonth   : int  7 5 4 6 5 6 6 8 9 20 ...\n $ AcceptedCmp3        : int  0 0 0 0 0 0 0 0 0 1 ...\n $ AcceptedCmp4        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ AcceptedCmp5        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ AcceptedCmp1        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ AcceptedCmp2        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Complain            : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Z_CostContact       : int  3 3 3 3 3 3 3 3 3 3 ...\n $ Z_Revenue           : int  11 11 11 11 11 11 11 11 11 11 ...\n $ Response            : int  1 0 0 0 0 0 0 0 1 0 ...\n $ Age                 : int  63 66 55 36 39 53 49 35 46 70 ...\n $ Customer_Days       : int  2822 2272 2471 2298 2320 2452 2752 2576 2547 2267 ...\n $ marital_Divorced    : int  0 0 0 0 0 0 1 0 0 0 ...\n $ marital_Married     : int  0 0 0 0 1 0 0 1 0 0 ...\n $ marital_Single      : int  1 1 0 0 0 0 0 0 0 0 ...\n $ marital_Together    : int  0 0 1 1 0 1 0 0 1 1 ...\n $ marital_Widow       : int  0 0 0 0 0 0 0 0 0 0 ...\n $ education_2n.Cycle  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ education_Basic     : int  0 0 0 0 0 0 0 0 0 0 ...\n $ education_Graduation: int  1 1 1 1 0 0 1 0 0 0 ...\n $ education_Master    : int  0 0 0 0 0 1 0 0 0 0 ...\n $ education_PhD       : int  0 0 0 0 1 0 0 1 1 1 ...\n $ MntTotal            : int  1529 21 734 48 407 702 563 146 44 36 ...\n $ MntRegularProds     : int  1441 15 692 43 392 688 536 123 42 23 ...\n $ AcceptedCmpOverall  : int  0 0 0 0 0 0 0 0 0 1 ...\n\n\nThe psych package in R provides some useful function for describing data. Let’s install psyc, load the package, and look at our data.\n\ninstall.packages(\"psych\") # install the package\n\n\nlibrary(\"psych\") # load the library\n\n\n\n\nNow let’s use the describe() function from psych to look at our marketing data.\n\ndescribe(df) # describe our marketing data\n\n                     vars    n     mean       sd median  trimmed      mad  min\nIncome                  1 2205 51622.09 20713.06  51287 51625.17 24408.04 1730\nKidhome                 2 2205     0.44     0.54      0     0.40     0.00    0\nTeenhome                3 2205     0.51     0.54      0     0.48     0.00    0\nRecency                 4 2205    49.01    28.93     49    49.00    37.06    0\nMntWines                5 2205   306.16   337.49    178   251.45   249.08    0\nMntFruits               6 2205    26.40    39.78      8    17.12    11.86    0\nMntMeatProducts         7 2205   165.31   217.78     68   119.54    88.96    0\nMntFishProducts         8 2205    37.76    54.82     12    25.31    17.79    0\nMntSweetProducts        9 2205    27.13    41.13      8    17.48    11.86    0\nMntGoldProds           10 2205    44.06    51.74     25    33.57    28.17    0\nNumDealsPurchases      11 2205     2.32     1.89      2     1.97     1.48    0\nNumWebPurchases        12 2205     4.10     2.74      4     3.83     2.97    0\nNumCatalogPurchases    13 2205     2.65     2.80      2     2.22     2.97    0\nNumStorePurchases      14 2205     5.82     3.24      5     5.52     2.97    0\nNumWebVisitsMonth      15 2205     5.34     2.41      6     5.41     2.97    0\nAcceptedCmp3           16 2205     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp4           17 2205     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp5           18 2205     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp1           19 2205     0.06     0.25      0     0.00     0.00    0\nAcceptedCmp2           20 2205     0.01     0.12      0     0.00     0.00    0\nComplain               21 2205     0.01     0.09      0     0.00     0.00    0\nZ_CostContact          22 2205     3.00     0.00      3     3.00     0.00    3\nZ_Revenue              23 2205    11.00     0.00     11    11.00     0.00   11\nResponse               24 2205     0.15     0.36      0     0.06     0.00    0\nAge                    25 2205    51.10    11.71     50    51.04    13.34   24\nCustomer_Days          26 2205  2512.72   202.56   2515  2513.15   259.46 2159\nmarital_Divorced       27 2205     0.10     0.31      0     0.01     0.00    0\nmarital_Married        28 2205     0.39     0.49      0     0.36     0.00    0\nmarital_Single         29 2205     0.22     0.41      0     0.15     0.00    0\nmarital_Together       30 2205     0.26     0.44      0     0.20     0.00    0\nmarital_Widow          31 2205     0.03     0.18      0     0.00     0.00    0\neducation_2n.Cycle     32 2205     0.09     0.29      0     0.00     0.00    0\neducation_Basic        33 2205     0.02     0.15      0     0.00     0.00    0\neducation_Graduation   34 2205     0.50     0.50      1     0.51     0.00    0\neducation_Master       35 2205     0.17     0.37      0     0.08     0.00    0\neducation_PhD          36 2205     0.22     0.41      0     0.15     0.00    0\nMntTotal               37 2205   562.76   575.94    343   482.34   459.61    4\nMntRegularProds        38 2205   518.71   553.85    288   436.84   400.30 -283\nAcceptedCmpOverall     39 2205     0.30     0.68      0     0.13     0.00    0\n                        max  range  skew kurtosis     se\nIncome               113734 112004  0.01    -0.85 441.10\nKidhome                   2      2  0.63    -0.79   0.01\nTeenhome                  2      2  0.40    -0.99   0.01\nRecency                  99     99  0.00    -1.20   0.62\nMntWines               1493   1493  1.17     0.57   7.19\nMntFruits               199    199  2.10     4.03   0.85\nMntMeatProducts        1725   1725  1.82     3.23   4.64\nMntFishProducts         259    259  1.91     3.04   1.17\nMntSweetProducts        262    262  2.10     4.06   0.88\nMntGoldProds            321    321  1.83     3.13   1.10\nNumDealsPurchases        15     15  2.31     8.16   0.04\nNumWebPurchases          27     27  1.20     4.08   0.06\nNumCatalogPurchases      28     28  1.37     3.19   0.06\nNumStorePurchases        13     13  0.71    -0.64   0.07\nNumWebVisitsMonth        20     20  0.23     1.89   0.05\nAcceptedCmp3              1      1  3.25     8.60   0.01\nAcceptedCmp4              1      1  3.24     8.52   0.01\nAcceptedCmp5              1      1  3.28     8.76   0.01\nAcceptedCmp1              1      1  3.55    10.58   0.01\nAcceptedCmp2              1      1  8.39    68.45   0.00\nComplain                  1      1 10.35   105.16   0.00\nZ_CostContact             3      0   NaN      NaN   0.00\nZ_Revenue                11      0   NaN      NaN   0.00\nResponse                  1      1  1.95     1.80   0.01\nAge                      80     56  0.09    -0.80   0.25\nCustomer_Days          2858    699 -0.02    -1.20   4.31\nmarital_Divorced          1      1  2.59     4.70   0.01\nmarital_Married           1      1  0.46    -1.79   0.01\nmarital_Single            1      1  1.38    -0.10   0.01\nmarital_Together          1      1  1.11    -0.77   0.01\nmarital_Widow             1      1  5.10    24.02   0.00\neducation_2n.Cycle        1      1  2.87     6.23   0.01\neducation_Basic           1      1  6.15    35.82   0.00\neducation_Graduation      1      1 -0.02    -2.00   0.01\neducation_Master          1      1  1.80     1.25   0.01\neducation_PhD             1      1  1.38    -0.09   0.01\nMntTotal               2491   2487  0.91    -0.22  12.27\nMntRegularProds        2458   2741  0.98    -0.06  11.79\nAcceptedCmpOverall        4      4  2.72     7.94   0.01\n\n\n\n\n\nWe may also be interested in describing the data based on a specific grouping factor. For example, let’s look at our summaries based on whether or not a customer has lodged a formal complaint.\n\ndescribeBy(df, group = \"Complain\") # describe our marketing data\n\n\n Descriptive statistics by group \nComplain: 0\n                     vars    n     mean       sd median  trimmed      mad  min\nIncome                  1 2185 51676.55 20719.18  51369 51687.17 24529.62 1730\nKidhome                 2 2185     0.44     0.54      0     0.40     0.00    0\nTeenhome                3 2185     0.51     0.54      0     0.48     0.00    0\nRecency                 4 2185    48.99    28.95     49    48.98    37.06    0\nMntWines                5 2185   307.35   338.23    179   252.68   250.56    0\nMntFruits               6 2185    26.42    39.80      8    17.13    11.86    0\nMntMeatProducts         7 2185   165.75   218.21     68   119.91    88.96    0\nMntFishProducts         8 2185    37.86    54.95     12    25.37    17.79    0\nMntSweetProducts        9 2185    27.21    41.21      8    17.55    11.86    0\nMntGoldProds           10 2185    44.21    51.81     25    33.74    28.17    0\nNumDealsPurchases      11 2185     2.32     1.89      2     1.96     1.48    0\nNumWebPurchases        12 2185     4.10     2.74      4     3.83     2.97    0\nNumCatalogPurchases    13 2185     2.65     2.80      2     2.22     2.97    0\nNumStorePurchases      14 2185     5.83     3.24      5     5.52     2.97    0\nNumWebVisitsMonth      15 2185     5.33     2.41      6     5.41     2.97    0\nAcceptedCmp3           16 2185     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp4           17 2185     0.08     0.26      0     0.00     0.00    0\nAcceptedCmp5           18 2185     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp1           19 2185     0.06     0.25      0     0.00     0.00    0\nAcceptedCmp2           20 2185     0.01     0.12      0     0.00     0.00    0\nComplain               21 2185     0.00     0.00      0     0.00     0.00    0\nZ_CostContact          22 2185     3.00     0.00      3     3.00     0.00    3\nZ_Revenue              23 2185    11.00     0.00     11    11.00     0.00   11\nResponse               24 2185     0.15     0.36      0     0.06     0.00    0\nAge                    25 2185    51.09    11.68     50    51.03    13.34   24\nCustomer_Days          26 2185  2512.02   202.56   2514  2512.30   257.97 2159\nmarital_Divorced       27 2185     0.10     0.31      0     0.01     0.00    0\nmarital_Married        28 2185     0.39     0.49      0     0.36     0.00    0\nmarital_Single         29 2185     0.22     0.41      0     0.14     0.00    0\nmarital_Together       30 2185     0.26     0.44      0     0.20     0.00    0\nmarital_Widow          31 2185     0.03     0.18      0     0.00     0.00    0\neducation_2n.Cycle     32 2185     0.09     0.29      0     0.00     0.00    0\neducation_Basic        33 2185     0.02     0.16      0     0.00     0.00    0\neducation_Graduation   34 2185     0.50     0.50      1     0.50     0.00    0\neducation_Master       35 2185     0.17     0.37      0     0.08     0.00    0\neducation_PhD          36 2185     0.22     0.41      0     0.15     0.00    0\nMntTotal               37 2185   564.58   576.90    344   484.26   461.09    4\nMntRegularProds        38 2185   520.37   554.76    288   438.58   400.30 -283\nAcceptedCmpOverall     39 2185     0.30     0.68      0     0.14     0.00    0\n                        max  range  skew kurtosis     se\nIncome               113734 112004  0.01    -0.85 443.25\nKidhome                   2      2  0.64    -0.79   0.01\nTeenhome                  2      2  0.40    -1.00   0.01\nRecency                  99     99  0.00    -1.20   0.62\nMntWines               1493   1493  1.16     0.55   7.24\nMntFruits               199    199  2.10     4.05   0.85\nMntMeatProducts        1725   1725  1.81     3.22   4.67\nMntFishProducts         259    259  1.91     3.03   1.18\nMntSweetProducts        262    262  2.09     4.05   0.88\nMntGoldProds            321    321  1.83     3.11   1.11\nNumDealsPurchases        15     15  2.31     8.15   0.04\nNumWebPurchases          27     27  1.20     4.13   0.06\nNumCatalogPurchases      28     28  1.37     3.22   0.06\nNumStorePurchases        13     13  0.70    -0.64   0.07\nNumWebVisitsMonth        20     20  0.24     1.92   0.05\nAcceptedCmp3              1      1  3.26     8.64   0.01\nAcceptedCmp4              1      1  3.22     8.39   0.01\nAcceptedCmp5              1      1  3.27     8.72   0.01\nAcceptedCmp1              1      1  3.53    10.44   0.01\nAcceptedCmp2              1      1  8.35    67.78   0.00\nComplain                  0      0   NaN      NaN   0.00\nZ_CostContact             3      0   NaN      NaN   0.00\nZ_Revenue                11      0   NaN      NaN   0.00\nResponse                  1      1  1.95     1.79   0.01\nAge                      80     56  0.09    -0.80   0.25\nCustomer_Days          2858    699 -0.01    -1.20   4.33\nmarital_Divorced          1      1  2.58     4.65   0.01\nmarital_Married           1      1  0.46    -1.79   0.01\nmarital_Single            1      1  1.38    -0.09   0.01\nmarital_Together          1      1  1.11    -0.77   0.01\nmarital_Widow             1      1  5.07    23.76   0.00\neducation_2n.Cycle        1      1  2.88     6.29   0.01\neducation_Basic           1      1  6.12    35.45   0.00\neducation_Graduation      1      1 -0.01    -2.00   0.01\neducation_Master          1      1  1.80     1.23   0.01\neducation_PhD             1      1  1.37    -0.12   0.01\nMntTotal               2491   2487  0.91    -0.23  12.34\nMntRegularProds        2458   2741  0.98    -0.07  11.87\nAcceptedCmpOverall        4      4  2.71     7.91   0.01\n------------------------------------------------------------ \nComplain: 1\n                     vars  n     mean       sd  median  trimmed      mad   min\nIncome                  1 20 45672.40 19618.60 39341.0 44737.81 22307.94 15716\nKidhome                 2 20     0.65     0.59     1.0     0.62     0.00     0\nTeenhome                3 20     0.55     0.60     0.5     0.50     0.74     0\nRecency                 4 20    50.75    27.20    48.5    50.62    28.17     8\nMntWines                5 20   176.70   211.11    34.0   147.88    48.18     1\nMntFruits               6 20    25.10    39.13     6.0    16.31     8.90     0\nMntMeatProducts         7 20   117.70   162.23    32.5    85.00    45.96     1\nMntFishProducts         8 20    26.70    38.73     6.5    20.50     9.64     0\nMntSweetProducts        9 20    18.20    31.36     4.5    11.19     5.93     0\nMntGoldProds           10 20    27.60    40.93    13.5    18.00    12.60     2\nNumDealsPurchases      11 20     2.40     1.43     2.0     2.19     1.48     1\nNumWebPurchases        12 20     3.70     2.96     3.0     3.31     2.22     0\nNumCatalogPurchases    13 20     2.10     2.90     0.5     1.56     0.74     0\nNumStorePurchases      14 20     5.40     3.60     3.5     4.94     2.22     2\nNumWebVisitsMonth      15 20     5.85     2.41     7.0     6.06     1.48     1\nAcceptedCmp3           16 20     0.10     0.31     0.0     0.00     0.00     0\nAcceptedCmp4           17 20     0.00     0.00     0.0     0.00     0.00     0\nAcceptedCmp5           18 20     0.05     0.22     0.0     0.00     0.00     0\nAcceptedCmp1           19 20     0.00     0.00     0.0     0.00     0.00     0\nAcceptedCmp2           20 20     0.00     0.00     0.0     0.00     0.00     0\nComplain               21 20     1.00     0.00     1.0     1.00     0.00     1\nZ_CostContact          22 20     3.00     0.00     3.0     3.00     0.00     3\nZ_Revenue              23 20    11.00     0.00    11.0    11.00     0.00    11\nResponse               24 20     0.15     0.37     0.0     0.06     0.00     0\nAge                    25 20    51.65    15.04    50.0    51.81    17.79    25\nCustomer_Days          26 20  2588.70   193.28  2685.0  2602.06   164.57  2250\nmarital_Divorced       27 20     0.05     0.22     0.0     0.00     0.00     0\nmarital_Married        28 20     0.40     0.50     0.0     0.38     0.00     0\nmarital_Single         29 20     0.30     0.47     0.0     0.25     0.00     0\nmarital_Together       30 20     0.25     0.44     0.0     0.19     0.00     0\nmarital_Widow          31 20     0.00     0.00     0.0     0.00     0.00     0\neducation_2n.Cycle     32 20     0.15     0.37     0.0     0.06     0.00     0\neducation_Basic        33 20     0.00     0.00     0.0     0.00     0.00     0\neducation_Graduation   34 20     0.70     0.47     1.0     0.75     0.00     0\neducation_Master       35 20     0.10     0.31     0.0     0.00     0.00     0\neducation_PhD          36 20     0.05     0.22     0.0     0.00     0.00     0\nMntTotal               37 20   364.40   424.05    77.5   300.19   101.56     9\nMntRegularProds        38 20   336.80   414.50    63.5   271.94    84.51     0\nAcceptedCmpOverall     39 20     0.15     0.49     0.0     0.00     0.00     0\n                       max range  skew kurtosis      se\nIncome               83257 67541  0.35    -0.97 4386.85\nKidhome                  2     2  0.18    -0.93    0.13\nTeenhome                 2     2  0.50    -0.87    0.14\nRecency                 93    85  0.11    -1.28    6.08\nMntWines               629   628  0.84    -0.88   47.21\nMntFruits              137   137  1.58     1.39    8.75\nMntMeatProducts        590   589  1.58     1.50   36.28\nMntFishProducts        104   104  1.05    -0.69    8.66\nMntSweetProducts       107   107  1.74     1.58    7.01\nMntGoldProds           176   174  2.48     5.90    9.15\nNumDealsPurchases        7     6  1.48     2.74    0.32\nNumWebPurchases         11    11  1.01    -0.07    0.66\nNumCatalogPurchases     10    10  1.25     0.52    0.65\nNumStorePurchases       13    11  0.87    -0.81    0.81\nNumWebVisitsMonth        9     8 -0.67    -1.02    0.54\nAcceptedCmp3             1     1  2.47     4.32    0.07\nAcceptedCmp4             0     0   NaN      NaN    0.00\nAcceptedCmp5             1     1  3.82    13.29    0.05\nAcceptedCmp1             0     0   NaN      NaN    0.00\nAcceptedCmp2             0     0   NaN      NaN    0.00\nComplain                 1     0   NaN      NaN    0.00\nZ_CostContact            3     0   NaN      NaN    0.00\nZ_Revenue               11     0   NaN      NaN    0.00\nResponse                 1     1  1.82     1.37    0.08\nAge                     77    52 -0.02    -1.46    3.36\nCustomer_Days         2823   573 -0.49    -1.30   43.22\nmarital_Divorced         1     1  3.82    13.29    0.05\nmarital_Married          1     1  0.38    -1.95    0.11\nmarital_Single           1     1  0.81    -1.41    0.11\nmarital_Together         1     1  1.07    -0.89    0.10\nmarital_Widow            0     0   NaN      NaN    0.00\neducation_2n.Cycle       1     1  1.82     1.37    0.08\neducation_Basic          0     0   NaN      NaN    0.00\neducation_Graduation     1     1 -0.81    -1.41    0.11\neducation_Master         1     1  2.47     4.32    0.07\neducation_PhD            1     1  3.82    13.29    0.05\nMntTotal              1298  1289  0.85    -0.73   94.82\nMntRegularProds       1231  1231  0.90    -0.72   92.68\nAcceptedCmpOverall       2     2  2.94     7.68    0.11",
    "crumbs": [
      "Introduction to R",
      "Describing Data Numerically"
    ]
  },
  {
    "objectID": "week1_3.html#numerical-summaries-of-data-frames",
    "href": "week1_3.html#numerical-summaries-of-data-frames",
    "title": "Describing Data Numerically",
    "section": "",
    "text": "Once you have read in a data frame it can be useful to know how the variables are understood by R. For example, let’s look at some Kaggle Marketing Analytics Data. You can download the raw data here.\n\n\n\nData dictionary for marketing data\n\n\n\n\nLet’s read in the data using the read.csv() function.\n\nsetwd(\"/Users/zacharyfisher/Dropbox/Macbook/UNC/Teaching/Courses/PSYC559/PSYC559-Site/data\")\ndf &lt;- read.csv(\"ifood_df.csv\")\n\n\n\n\nOnce we know the data has been read into R we can look at how R understands the data file using the structure function str()\n\nstr(df)\n\n'data.frame':   2205 obs. of  39 variables:\n $ Income              : num  58138 46344 71613 26646 58293 ...\n $ Kidhome             : int  0 1 0 1 1 0 0 1 1 1 ...\n $ Teenhome            : int  0 1 0 0 0 1 1 0 0 1 ...\n $ Recency             : int  58 38 26 26 94 16 34 32 19 68 ...\n $ MntWines            : int  635 11 426 11 173 520 235 76 14 28 ...\n $ MntFruits           : int  88 1 49 4 43 42 65 10 0 0 ...\n $ MntMeatProducts     : int  546 6 127 20 118 98 164 56 24 6 ...\n $ MntFishProducts     : int  172 2 111 10 46 0 50 3 3 1 ...\n $ MntSweetProducts    : int  88 1 21 3 27 42 49 1 3 1 ...\n $ MntGoldProds        : int  88 6 42 5 15 14 27 23 2 13 ...\n $ NumDealsPurchases   : int  3 2 1 2 5 2 4 2 1 1 ...\n $ NumWebPurchases     : int  8 1 8 2 5 6 7 4 3 1 ...\n $ NumCatalogPurchases : int  10 1 2 0 3 4 3 0 0 0 ...\n $ NumStorePurchases   : int  4 2 10 4 6 10 7 4 2 0 ...\n $ NumWebVisitsMonth   : int  7 5 4 6 5 6 6 8 9 20 ...\n $ AcceptedCmp3        : int  0 0 0 0 0 0 0 0 0 1 ...\n $ AcceptedCmp4        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ AcceptedCmp5        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ AcceptedCmp1        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ AcceptedCmp2        : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Complain            : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Z_CostContact       : int  3 3 3 3 3 3 3 3 3 3 ...\n $ Z_Revenue           : int  11 11 11 11 11 11 11 11 11 11 ...\n $ Response            : int  1 0 0 0 0 0 0 0 1 0 ...\n $ Age                 : int  63 66 55 36 39 53 49 35 46 70 ...\n $ Customer_Days       : int  2822 2272 2471 2298 2320 2452 2752 2576 2547 2267 ...\n $ marital_Divorced    : int  0 0 0 0 0 0 1 0 0 0 ...\n $ marital_Married     : int  0 0 0 0 1 0 0 1 0 0 ...\n $ marital_Single      : int  1 1 0 0 0 0 0 0 0 0 ...\n $ marital_Together    : int  0 0 1 1 0 1 0 0 1 1 ...\n $ marital_Widow       : int  0 0 0 0 0 0 0 0 0 0 ...\n $ education_2n.Cycle  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ education_Basic     : int  0 0 0 0 0 0 0 0 0 0 ...\n $ education_Graduation: int  1 1 1 1 0 0 1 0 0 0 ...\n $ education_Master    : int  0 0 0 0 0 1 0 0 0 0 ...\n $ education_PhD       : int  0 0 0 0 1 0 0 1 1 1 ...\n $ MntTotal            : int  1529 21 734 48 407 702 563 146 44 36 ...\n $ MntRegularProds     : int  1441 15 692 43 392 688 536 123 42 23 ...\n $ AcceptedCmpOverall  : int  0 0 0 0 0 0 0 0 0 1 ...\n\n\nThe psych package in R provides some useful function for describing data. Let’s install psyc, load the package, and look at our data.\n\ninstall.packages(\"psych\") # install the package\n\n\nlibrary(\"psych\") # load the library\n\n\n\n\nNow let’s use the describe() function from psych to look at our marketing data.\n\ndescribe(df) # describe our marketing data\n\n                     vars    n     mean       sd median  trimmed      mad  min\nIncome                  1 2205 51622.09 20713.06  51287 51625.17 24408.04 1730\nKidhome                 2 2205     0.44     0.54      0     0.40     0.00    0\nTeenhome                3 2205     0.51     0.54      0     0.48     0.00    0\nRecency                 4 2205    49.01    28.93     49    49.00    37.06    0\nMntWines                5 2205   306.16   337.49    178   251.45   249.08    0\nMntFruits               6 2205    26.40    39.78      8    17.12    11.86    0\nMntMeatProducts         7 2205   165.31   217.78     68   119.54    88.96    0\nMntFishProducts         8 2205    37.76    54.82     12    25.31    17.79    0\nMntSweetProducts        9 2205    27.13    41.13      8    17.48    11.86    0\nMntGoldProds           10 2205    44.06    51.74     25    33.57    28.17    0\nNumDealsPurchases      11 2205     2.32     1.89      2     1.97     1.48    0\nNumWebPurchases        12 2205     4.10     2.74      4     3.83     2.97    0\nNumCatalogPurchases    13 2205     2.65     2.80      2     2.22     2.97    0\nNumStorePurchases      14 2205     5.82     3.24      5     5.52     2.97    0\nNumWebVisitsMonth      15 2205     5.34     2.41      6     5.41     2.97    0\nAcceptedCmp3           16 2205     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp4           17 2205     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp5           18 2205     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp1           19 2205     0.06     0.25      0     0.00     0.00    0\nAcceptedCmp2           20 2205     0.01     0.12      0     0.00     0.00    0\nComplain               21 2205     0.01     0.09      0     0.00     0.00    0\nZ_CostContact          22 2205     3.00     0.00      3     3.00     0.00    3\nZ_Revenue              23 2205    11.00     0.00     11    11.00     0.00   11\nResponse               24 2205     0.15     0.36      0     0.06     0.00    0\nAge                    25 2205    51.10    11.71     50    51.04    13.34   24\nCustomer_Days          26 2205  2512.72   202.56   2515  2513.15   259.46 2159\nmarital_Divorced       27 2205     0.10     0.31      0     0.01     0.00    0\nmarital_Married        28 2205     0.39     0.49      0     0.36     0.00    0\nmarital_Single         29 2205     0.22     0.41      0     0.15     0.00    0\nmarital_Together       30 2205     0.26     0.44      0     0.20     0.00    0\nmarital_Widow          31 2205     0.03     0.18      0     0.00     0.00    0\neducation_2n.Cycle     32 2205     0.09     0.29      0     0.00     0.00    0\neducation_Basic        33 2205     0.02     0.15      0     0.00     0.00    0\neducation_Graduation   34 2205     0.50     0.50      1     0.51     0.00    0\neducation_Master       35 2205     0.17     0.37      0     0.08     0.00    0\neducation_PhD          36 2205     0.22     0.41      0     0.15     0.00    0\nMntTotal               37 2205   562.76   575.94    343   482.34   459.61    4\nMntRegularProds        38 2205   518.71   553.85    288   436.84   400.30 -283\nAcceptedCmpOverall     39 2205     0.30     0.68      0     0.13     0.00    0\n                        max  range  skew kurtosis     se\nIncome               113734 112004  0.01    -0.85 441.10\nKidhome                   2      2  0.63    -0.79   0.01\nTeenhome                  2      2  0.40    -0.99   0.01\nRecency                  99     99  0.00    -1.20   0.62\nMntWines               1493   1493  1.17     0.57   7.19\nMntFruits               199    199  2.10     4.03   0.85\nMntMeatProducts        1725   1725  1.82     3.23   4.64\nMntFishProducts         259    259  1.91     3.04   1.17\nMntSweetProducts        262    262  2.10     4.06   0.88\nMntGoldProds            321    321  1.83     3.13   1.10\nNumDealsPurchases        15     15  2.31     8.16   0.04\nNumWebPurchases          27     27  1.20     4.08   0.06\nNumCatalogPurchases      28     28  1.37     3.19   0.06\nNumStorePurchases        13     13  0.71    -0.64   0.07\nNumWebVisitsMonth        20     20  0.23     1.89   0.05\nAcceptedCmp3              1      1  3.25     8.60   0.01\nAcceptedCmp4              1      1  3.24     8.52   0.01\nAcceptedCmp5              1      1  3.28     8.76   0.01\nAcceptedCmp1              1      1  3.55    10.58   0.01\nAcceptedCmp2              1      1  8.39    68.45   0.00\nComplain                  1      1 10.35   105.16   0.00\nZ_CostContact             3      0   NaN      NaN   0.00\nZ_Revenue                11      0   NaN      NaN   0.00\nResponse                  1      1  1.95     1.80   0.01\nAge                      80     56  0.09    -0.80   0.25\nCustomer_Days          2858    699 -0.02    -1.20   4.31\nmarital_Divorced          1      1  2.59     4.70   0.01\nmarital_Married           1      1  0.46    -1.79   0.01\nmarital_Single            1      1  1.38    -0.10   0.01\nmarital_Together          1      1  1.11    -0.77   0.01\nmarital_Widow             1      1  5.10    24.02   0.00\neducation_2n.Cycle        1      1  2.87     6.23   0.01\neducation_Basic           1      1  6.15    35.82   0.00\neducation_Graduation      1      1 -0.02    -2.00   0.01\neducation_Master          1      1  1.80     1.25   0.01\neducation_PhD             1      1  1.38    -0.09   0.01\nMntTotal               2491   2487  0.91    -0.22  12.27\nMntRegularProds        2458   2741  0.98    -0.06  11.79\nAcceptedCmpOverall        4      4  2.72     7.94   0.01\n\n\n\n\n\nWe may also be interested in describing the data based on a specific grouping factor. For example, let’s look at our summaries based on whether or not a customer has lodged a formal complaint.\n\ndescribeBy(df, group = \"Complain\") # describe our marketing data\n\n\n Descriptive statistics by group \nComplain: 0\n                     vars    n     mean       sd median  trimmed      mad  min\nIncome                  1 2185 51676.55 20719.18  51369 51687.17 24529.62 1730\nKidhome                 2 2185     0.44     0.54      0     0.40     0.00    0\nTeenhome                3 2185     0.51     0.54      0     0.48     0.00    0\nRecency                 4 2185    48.99    28.95     49    48.98    37.06    0\nMntWines                5 2185   307.35   338.23    179   252.68   250.56    0\nMntFruits               6 2185    26.42    39.80      8    17.13    11.86    0\nMntMeatProducts         7 2185   165.75   218.21     68   119.91    88.96    0\nMntFishProducts         8 2185    37.86    54.95     12    25.37    17.79    0\nMntSweetProducts        9 2185    27.21    41.21      8    17.55    11.86    0\nMntGoldProds           10 2185    44.21    51.81     25    33.74    28.17    0\nNumDealsPurchases      11 2185     2.32     1.89      2     1.96     1.48    0\nNumWebPurchases        12 2185     4.10     2.74      4     3.83     2.97    0\nNumCatalogPurchases    13 2185     2.65     2.80      2     2.22     2.97    0\nNumStorePurchases      14 2185     5.83     3.24      5     5.52     2.97    0\nNumWebVisitsMonth      15 2185     5.33     2.41      6     5.41     2.97    0\nAcceptedCmp3           16 2185     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp4           17 2185     0.08     0.26      0     0.00     0.00    0\nAcceptedCmp5           18 2185     0.07     0.26      0     0.00     0.00    0\nAcceptedCmp1           19 2185     0.06     0.25      0     0.00     0.00    0\nAcceptedCmp2           20 2185     0.01     0.12      0     0.00     0.00    0\nComplain               21 2185     0.00     0.00      0     0.00     0.00    0\nZ_CostContact          22 2185     3.00     0.00      3     3.00     0.00    3\nZ_Revenue              23 2185    11.00     0.00     11    11.00     0.00   11\nResponse               24 2185     0.15     0.36      0     0.06     0.00    0\nAge                    25 2185    51.09    11.68     50    51.03    13.34   24\nCustomer_Days          26 2185  2512.02   202.56   2514  2512.30   257.97 2159\nmarital_Divorced       27 2185     0.10     0.31      0     0.01     0.00    0\nmarital_Married        28 2185     0.39     0.49      0     0.36     0.00    0\nmarital_Single         29 2185     0.22     0.41      0     0.14     0.00    0\nmarital_Together       30 2185     0.26     0.44      0     0.20     0.00    0\nmarital_Widow          31 2185     0.03     0.18      0     0.00     0.00    0\neducation_2n.Cycle     32 2185     0.09     0.29      0     0.00     0.00    0\neducation_Basic        33 2185     0.02     0.16      0     0.00     0.00    0\neducation_Graduation   34 2185     0.50     0.50      1     0.50     0.00    0\neducation_Master       35 2185     0.17     0.37      0     0.08     0.00    0\neducation_PhD          36 2185     0.22     0.41      0     0.15     0.00    0\nMntTotal               37 2185   564.58   576.90    344   484.26   461.09    4\nMntRegularProds        38 2185   520.37   554.76    288   438.58   400.30 -283\nAcceptedCmpOverall     39 2185     0.30     0.68      0     0.14     0.00    0\n                        max  range  skew kurtosis     se\nIncome               113734 112004  0.01    -0.85 443.25\nKidhome                   2      2  0.64    -0.79   0.01\nTeenhome                  2      2  0.40    -1.00   0.01\nRecency                  99     99  0.00    -1.20   0.62\nMntWines               1493   1493  1.16     0.55   7.24\nMntFruits               199    199  2.10     4.05   0.85\nMntMeatProducts        1725   1725  1.81     3.22   4.67\nMntFishProducts         259    259  1.91     3.03   1.18\nMntSweetProducts        262    262  2.09     4.05   0.88\nMntGoldProds            321    321  1.83     3.11   1.11\nNumDealsPurchases        15     15  2.31     8.15   0.04\nNumWebPurchases          27     27  1.20     4.13   0.06\nNumCatalogPurchases      28     28  1.37     3.22   0.06\nNumStorePurchases        13     13  0.70    -0.64   0.07\nNumWebVisitsMonth        20     20  0.24     1.92   0.05\nAcceptedCmp3              1      1  3.26     8.64   0.01\nAcceptedCmp4              1      1  3.22     8.39   0.01\nAcceptedCmp5              1      1  3.27     8.72   0.01\nAcceptedCmp1              1      1  3.53    10.44   0.01\nAcceptedCmp2              1      1  8.35    67.78   0.00\nComplain                  0      0   NaN      NaN   0.00\nZ_CostContact             3      0   NaN      NaN   0.00\nZ_Revenue                11      0   NaN      NaN   0.00\nResponse                  1      1  1.95     1.79   0.01\nAge                      80     56  0.09    -0.80   0.25\nCustomer_Days          2858    699 -0.01    -1.20   4.33\nmarital_Divorced          1      1  2.58     4.65   0.01\nmarital_Married           1      1  0.46    -1.79   0.01\nmarital_Single            1      1  1.38    -0.09   0.01\nmarital_Together          1      1  1.11    -0.77   0.01\nmarital_Widow             1      1  5.07    23.76   0.00\neducation_2n.Cycle        1      1  2.88     6.29   0.01\neducation_Basic           1      1  6.12    35.45   0.00\neducation_Graduation      1      1 -0.01    -2.00   0.01\neducation_Master          1      1  1.80     1.23   0.01\neducation_PhD             1      1  1.37    -0.12   0.01\nMntTotal               2491   2487  0.91    -0.23  12.34\nMntRegularProds        2458   2741  0.98    -0.07  11.87\nAcceptedCmpOverall        4      4  2.71     7.91   0.01\n------------------------------------------------------------ \nComplain: 1\n                     vars  n     mean       sd  median  trimmed      mad   min\nIncome                  1 20 45672.40 19618.60 39341.0 44737.81 22307.94 15716\nKidhome                 2 20     0.65     0.59     1.0     0.62     0.00     0\nTeenhome                3 20     0.55     0.60     0.5     0.50     0.74     0\nRecency                 4 20    50.75    27.20    48.5    50.62    28.17     8\nMntWines                5 20   176.70   211.11    34.0   147.88    48.18     1\nMntFruits               6 20    25.10    39.13     6.0    16.31     8.90     0\nMntMeatProducts         7 20   117.70   162.23    32.5    85.00    45.96     1\nMntFishProducts         8 20    26.70    38.73     6.5    20.50     9.64     0\nMntSweetProducts        9 20    18.20    31.36     4.5    11.19     5.93     0\nMntGoldProds           10 20    27.60    40.93    13.5    18.00    12.60     2\nNumDealsPurchases      11 20     2.40     1.43     2.0     2.19     1.48     1\nNumWebPurchases        12 20     3.70     2.96     3.0     3.31     2.22     0\nNumCatalogPurchases    13 20     2.10     2.90     0.5     1.56     0.74     0\nNumStorePurchases      14 20     5.40     3.60     3.5     4.94     2.22     2\nNumWebVisitsMonth      15 20     5.85     2.41     7.0     6.06     1.48     1\nAcceptedCmp3           16 20     0.10     0.31     0.0     0.00     0.00     0\nAcceptedCmp4           17 20     0.00     0.00     0.0     0.00     0.00     0\nAcceptedCmp5           18 20     0.05     0.22     0.0     0.00     0.00     0\nAcceptedCmp1           19 20     0.00     0.00     0.0     0.00     0.00     0\nAcceptedCmp2           20 20     0.00     0.00     0.0     0.00     0.00     0\nComplain               21 20     1.00     0.00     1.0     1.00     0.00     1\nZ_CostContact          22 20     3.00     0.00     3.0     3.00     0.00     3\nZ_Revenue              23 20    11.00     0.00    11.0    11.00     0.00    11\nResponse               24 20     0.15     0.37     0.0     0.06     0.00     0\nAge                    25 20    51.65    15.04    50.0    51.81    17.79    25\nCustomer_Days          26 20  2588.70   193.28  2685.0  2602.06   164.57  2250\nmarital_Divorced       27 20     0.05     0.22     0.0     0.00     0.00     0\nmarital_Married        28 20     0.40     0.50     0.0     0.38     0.00     0\nmarital_Single         29 20     0.30     0.47     0.0     0.25     0.00     0\nmarital_Together       30 20     0.25     0.44     0.0     0.19     0.00     0\nmarital_Widow          31 20     0.00     0.00     0.0     0.00     0.00     0\neducation_2n.Cycle     32 20     0.15     0.37     0.0     0.06     0.00     0\neducation_Basic        33 20     0.00     0.00     0.0     0.00     0.00     0\neducation_Graduation   34 20     0.70     0.47     1.0     0.75     0.00     0\neducation_Master       35 20     0.10     0.31     0.0     0.00     0.00     0\neducation_PhD          36 20     0.05     0.22     0.0     0.00     0.00     0\nMntTotal               37 20   364.40   424.05    77.5   300.19   101.56     9\nMntRegularProds        38 20   336.80   414.50    63.5   271.94    84.51     0\nAcceptedCmpOverall     39 20     0.15     0.49     0.0     0.00     0.00     0\n                       max range  skew kurtosis      se\nIncome               83257 67541  0.35    -0.97 4386.85\nKidhome                  2     2  0.18    -0.93    0.13\nTeenhome                 2     2  0.50    -0.87    0.14\nRecency                 93    85  0.11    -1.28    6.08\nMntWines               629   628  0.84    -0.88   47.21\nMntFruits              137   137  1.58     1.39    8.75\nMntMeatProducts        590   589  1.58     1.50   36.28\nMntFishProducts        104   104  1.05    -0.69    8.66\nMntSweetProducts       107   107  1.74     1.58    7.01\nMntGoldProds           176   174  2.48     5.90    9.15\nNumDealsPurchases        7     6  1.48     2.74    0.32\nNumWebPurchases         11    11  1.01    -0.07    0.66\nNumCatalogPurchases     10    10  1.25     0.52    0.65\nNumStorePurchases       13    11  0.87    -0.81    0.81\nNumWebVisitsMonth        9     8 -0.67    -1.02    0.54\nAcceptedCmp3             1     1  2.47     4.32    0.07\nAcceptedCmp4             0     0   NaN      NaN    0.00\nAcceptedCmp5             1     1  3.82    13.29    0.05\nAcceptedCmp1             0     0   NaN      NaN    0.00\nAcceptedCmp2             0     0   NaN      NaN    0.00\nComplain                 1     0   NaN      NaN    0.00\nZ_CostContact            3     0   NaN      NaN    0.00\nZ_Revenue               11     0   NaN      NaN    0.00\nResponse                 1     1  1.82     1.37    0.08\nAge                     77    52 -0.02    -1.46    3.36\nCustomer_Days         2823   573 -0.49    -1.30   43.22\nmarital_Divorced         1     1  3.82    13.29    0.05\nmarital_Married          1     1  0.38    -1.95    0.11\nmarital_Single           1     1  0.81    -1.41    0.11\nmarital_Together         1     1  1.07    -0.89    0.10\nmarital_Widow            0     0   NaN      NaN    0.00\neducation_2n.Cycle       1     1  1.82     1.37    0.08\neducation_Basic          0     0   NaN      NaN    0.00\neducation_Graduation     1     1 -0.81    -1.41    0.11\neducation_Master         1     1  2.47     4.32    0.07\neducation_PhD            1     1  3.82    13.29    0.05\nMntTotal              1298  1289  0.85    -0.73   94.82\nMntRegularProds       1231  1231  0.90    -0.72   92.68\nAcceptedCmpOverall       2     2  2.94     7.68    0.11",
    "crumbs": [
      "Introduction to R",
      "Describing Data Numerically"
    ]
  },
  {
    "objectID": "week1_1.html",
    "href": "week1_1.html",
    "title": "Basic R Programming",
    "section": "",
    "text": "Before getting started we will need to install R and RStudio.\n\n\nWe can download R from CRAN, the comprehensive R archive network. CRAN is a server used to distribute R and R packages. If you don’t have R installed already you can do so here.\n\n\n\nWith R installed, let’s go ahead and install RStudio. RStudio is a convenient IDE (integrated development environment) for R programming. Download and install the RStudio Desktop client.\n\n\n\nFrom the RStudio Education page:\n\nFor beginner-friendly installation instructions, we recommend the free online ModernDive chapter Getting Started with R and RStudio. You may also enjoy the Basic Basics lesson unit from R-Ladies Sydney, which provides an opinionated tour of RStudio for new users and a step-by-step guide to installing and using R packages.\n\n\n\n\nFor those of you who may be unfamiliar with using an IDE, RStudio is simply a convenient way for us to interact with R. You can think of R as the engine, powering the car, and RStudio as the controls and dashboard for driving. For 559, we won’t interact directly with R very often, instead we will work with R directly from RStudio.\n\n\n\nImage from https://moderndive.com/1-getting-started.html\n\n\n\n\n\nAfter opening RStudio you will see something similar to the image below, where the application is divided into different panes. Each pane serves a different purpose:\n\nQ1: contains scripts you are working from and sometimes data views\nQ2: the console where you run the code\nQ3: the environment page, code history, and build tools\nQ4: files, plots, packages, help documentation\n\n\n\n\nImage from https://rladiessydney.org/courses/01-basicbasics-1\n\n\n\n\n\nLet’s begin by using the Console to interact with R.\n\n\nWe can use R as a basic calculator.\n\n1 / 200 * 30\n#&gt; [1] 0.15\n(59 + 73 + 2) / 3\n#&gt; [1] 44.66667\nsin(pi / 2)\n#&gt; [1] 1\n\n\n\n\nWe can create new object using the assignment operator &lt;- as follows:\n\nx &lt;- 3 * 4\nsecret_password &lt;- \"password1234\"\n\nIn R, object names are case sensitive, must start with a letter and can contain numbers, letters, underscores and periods.\nYou can look at objects by typing their name into the console:\n\nx\n\n[1] 12\n\n\n\nsecret_password\n\n[1] \"password1234\"\n\n\nIf you type an object that hasn’t been defined yet you will get an error. For example,\n\nSecret_Password\n\nError: object 'Secret_Password' not found\n\n\n\n\n\nR has many built-in functions and you can also create your own. Functions can be used to perform tasks in R. They take arguments as inputs, and return outputs. Often you will supply arguments to a function, and it is also possible to use a function’s default values.\nFor example, there is a function in R called seq(from, to) that creates a sequence of numbers starting at from and ending at to. For example, if we want a sequences of numbers from = 10 all the way to = 20:\n\n# you can add comments to your code using the # key\n# anything after the # will not be run as code\n# note the code below is equivalent to seq(10, 20)\n\nseq(from = 10, to = 20) \n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\nIf you want to better understand what a specific function in R does you can always look to the documentation by typing a question mark before the function name in the R console, for example ?seq or ?rep.\n\n?seq\n\n\n\n\nIt is good practice to add comments to your code. These comments can help others understand what you are doing, and more importantly, they will help you remember what you did. How to effectively use comments is part of a larger discussion on how to write effective and understandable code, and if you’re interested take a look at different style guides for R.\n\n# you can add comments to your code using the # key \n# anything after the # will not be run as code \n#\n# note: the code below is equivalent to seq(10, 20)\n\nseq(from = 10, to = 20)\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\n\n\n\nFour of the most common data types used in R are discussed below:\n\nNumeric: The most common data type in R is numeric. A variable or a series will be stored as numeric data if the values are numbers or if the values contains decimals. For example, the following two series are stored as numeric by default:\n\n# numeric series without decimals\nnum_data &lt;- c(3, 7, 2)\nnum_data\n\n[1] 3 7 2\n\nclass(num_data)\n\n[1] \"numeric\"\n\n# numeric series with decimals\nnum_data_dec &lt;- c(3.4, 7.1, 2.9)\nnum_data_dec\n\n[1] 3.4 7.1 2.9\n\nclass(num_data_dec)\n\n[1] \"numeric\"\n\n\nCharacter: The data type character is used when storing text, known as strings in R. The simplest ways to store data under the character format is by using \"\" around the piece of text:\n\nchar &lt;- \"some text\"\nchar\n\n[1] \"some text\"\n\nclass(char)\n\n[1] \"character\"\n\n\nFactor: Factor variables are a special case of character variables in the sense that it also contains text. However, factor variables are used when there are a limited number of unique character strings. It often represents a categorical variable.\n\ntext &lt;- c(\"test1\", \"test2\", \"test1\", \"test1\") # create a character vector\nclass(text) # to know the class\n\n[1] \"character\"\n\ntext_factor &lt;- as.factor(text) # transform to factor\nclass(text_factor) # recheck the class\n\n[1] \"factor\"\n\n\nLogical: A logical variable is a variable with only two values; TRUE or FALSE\n\nvalue1 &lt;- 7\nvalue2 &lt;- 9\n\n# is value1 greater than value2?\ngreater &lt;- value1 &gt; value2\ngreater\n\n[1] FALSE\n\nclass(greater)\n\n[1] \"logical\"\n\n\n\nThese are four common R data types you’ll see in this class. There are others not listed here. For more detailed descriptions of data types in R there are a number of helpful resources available online, including this discussion of data structures.\n\n\n\nConditional statements are another useful R tool. These operators work similar in other programming languages but may look unfamiliar if you don’t have experience with R.\n\n\n\nx &lt;- 10\n\nif (x &gt; 6) {\n  print(\"x is greater than 6\")\n}\n\n[1] \"x is greater than 6\"\n\n\n\n\n\n\nx &lt;- 3\n\nif (x &gt; 6) {\n  print(\"x is greater than 6\")\n} else {\n  print(\"x is less than or equal to 6\")\n}\n\n[1] \"x is less than or equal to 6\"\n\n\nNested If Statements\n\nx &lt;- 8\ny &lt;- 3\n\nif (x &gt; 6) {\n  if (y &lt; 6) {\n    print(\"x is greater than 6 and y is less than 6\")\n  }\n}\n\n[1] \"x is greater than 6 and y is less than 6\"",
    "crumbs": [
      "Introduction to R",
      "Basic R Programming"
    ]
  },
  {
    "objectID": "week1_1.html#setting-up-your-environment",
    "href": "week1_1.html#setting-up-your-environment",
    "title": "Basic R Programming",
    "section": "",
    "text": "Before getting started we will need to install R and RStudio.\n\n\nWe can download R from CRAN, the comprehensive R archive network. CRAN is a server used to distribute R and R packages. If you don’t have R installed already you can do so here.\n\n\n\nWith R installed, let’s go ahead and install RStudio. RStudio is a convenient IDE (integrated development environment) for R programming. Download and install the RStudio Desktop client.\n\n\n\nFrom the RStudio Education page:\n\nFor beginner-friendly installation instructions, we recommend the free online ModernDive chapter Getting Started with R and RStudio. You may also enjoy the Basic Basics lesson unit from R-Ladies Sydney, which provides an opinionated tour of RStudio for new users and a step-by-step guide to installing and using R packages.\n\n\n\n\nFor those of you who may be unfamiliar with using an IDE, RStudio is simply a convenient way for us to interact with R. You can think of R as the engine, powering the car, and RStudio as the controls and dashboard for driving. For 559, we won’t interact directly with R very often, instead we will work with R directly from RStudio.\n\n\n\nImage from https://moderndive.com/1-getting-started.html\n\n\n\n\n\nAfter opening RStudio you will see something similar to the image below, where the application is divided into different panes. Each pane serves a different purpose:\n\nQ1: contains scripts you are working from and sometimes data views\nQ2: the console where you run the code\nQ3: the environment page, code history, and build tools\nQ4: files, plots, packages, help documentation\n\n\n\n\nImage from https://rladiessydney.org/courses/01-basicbasics-1\n\n\n\n\n\nLet’s begin by using the Console to interact with R.\n\n\nWe can use R as a basic calculator.\n\n1 / 200 * 30\n#&gt; [1] 0.15\n(59 + 73 + 2) / 3\n#&gt; [1] 44.66667\nsin(pi / 2)\n#&gt; [1] 1\n\n\n\n\nWe can create new object using the assignment operator &lt;- as follows:\n\nx &lt;- 3 * 4\nsecret_password &lt;- \"password1234\"\n\nIn R, object names are case sensitive, must start with a letter and can contain numbers, letters, underscores and periods.\nYou can look at objects by typing their name into the console:\n\nx\n\n[1] 12\n\n\n\nsecret_password\n\n[1] \"password1234\"\n\n\nIf you type an object that hasn’t been defined yet you will get an error. For example,\n\nSecret_Password\n\nError: object 'Secret_Password' not found\n\n\n\n\n\nR has many built-in functions and you can also create your own. Functions can be used to perform tasks in R. They take arguments as inputs, and return outputs. Often you will supply arguments to a function, and it is also possible to use a function’s default values.\nFor example, there is a function in R called seq(from, to) that creates a sequence of numbers starting at from and ending at to. For example, if we want a sequences of numbers from = 10 all the way to = 20:\n\n# you can add comments to your code using the # key\n# anything after the # will not be run as code\n# note the code below is equivalent to seq(10, 20)\n\nseq(from = 10, to = 20) \n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\nIf you want to better understand what a specific function in R does you can always look to the documentation by typing a question mark before the function name in the R console, for example ?seq or ?rep.\n\n?seq\n\n\n\n\nIt is good practice to add comments to your code. These comments can help others understand what you are doing, and more importantly, they will help you remember what you did. How to effectively use comments is part of a larger discussion on how to write effective and understandable code, and if you’re interested take a look at different style guides for R.\n\n# you can add comments to your code using the # key \n# anything after the # will not be run as code \n#\n# note: the code below is equivalent to seq(10, 20)\n\nseq(from = 10, to = 20)\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\n\n\n\nFour of the most common data types used in R are discussed below:\n\nNumeric: The most common data type in R is numeric. A variable or a series will be stored as numeric data if the values are numbers or if the values contains decimals. For example, the following two series are stored as numeric by default:\n\n# numeric series without decimals\nnum_data &lt;- c(3, 7, 2)\nnum_data\n\n[1] 3 7 2\n\nclass(num_data)\n\n[1] \"numeric\"\n\n# numeric series with decimals\nnum_data_dec &lt;- c(3.4, 7.1, 2.9)\nnum_data_dec\n\n[1] 3.4 7.1 2.9\n\nclass(num_data_dec)\n\n[1] \"numeric\"\n\n\nCharacter: The data type character is used when storing text, known as strings in R. The simplest ways to store data under the character format is by using \"\" around the piece of text:\n\nchar &lt;- \"some text\"\nchar\n\n[1] \"some text\"\n\nclass(char)\n\n[1] \"character\"\n\n\nFactor: Factor variables are a special case of character variables in the sense that it also contains text. However, factor variables are used when there are a limited number of unique character strings. It often represents a categorical variable.\n\ntext &lt;- c(\"test1\", \"test2\", \"test1\", \"test1\") # create a character vector\nclass(text) # to know the class\n\n[1] \"character\"\n\ntext_factor &lt;- as.factor(text) # transform to factor\nclass(text_factor) # recheck the class\n\n[1] \"factor\"\n\n\nLogical: A logical variable is a variable with only two values; TRUE or FALSE\n\nvalue1 &lt;- 7\nvalue2 &lt;- 9\n\n# is value1 greater than value2?\ngreater &lt;- value1 &gt; value2\ngreater\n\n[1] FALSE\n\nclass(greater)\n\n[1] \"logical\"\n\n\n\nThese are four common R data types you’ll see in this class. There are others not listed here. For more detailed descriptions of data types in R there are a number of helpful resources available online, including this discussion of data structures.\n\n\n\nConditional statements are another useful R tool. These operators work similar in other programming languages but may look unfamiliar if you don’t have experience with R.\n\n\n\nx &lt;- 10\n\nif (x &gt; 6) {\n  print(\"x is greater than 6\")\n}\n\n[1] \"x is greater than 6\"\n\n\n\n\n\n\nx &lt;- 3\n\nif (x &gt; 6) {\n  print(\"x is greater than 6\")\n} else {\n  print(\"x is less than or equal to 6\")\n}\n\n[1] \"x is less than or equal to 6\"\n\n\nNested If Statements\n\nx &lt;- 8\ny &lt;- 3\n\nif (x &gt; 6) {\n  if (y &lt; 6) {\n    print(\"x is greater than 6 and y is less than 6\")\n  }\n}\n\n[1] \"x is greater than 6 and y is less than 6\"",
    "crumbs": [
      "Introduction to R",
      "Basic R Programming"
    ]
  },
  {
    "objectID": "week2_2.html",
    "href": "week2_2.html",
    "title": "Problem Classes in ML",
    "section": "",
    "text": "Machine learning applications correspond to a wide variety of learning problems. Some major classes include:\nWe will now complete a short in-class exercise demonstrating how one might build a binary classification problem.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Problem Classes in ML"
    ]
  },
  {
    "objectID": "week2_2.html#classification",
    "href": "week2_2.html#classification",
    "title": "Problem Classes in ML",
    "section": "Classification",
    "text": "Classification\n\nThe goal of classification is often toassign a category or label to each observation.\nThe music genre problem is a good example of a classification problem\nNote: The number of categories can be small, large, or even unbounded (e.g., optical character recognition, text classification, speech recognition).\n\n\n\n\nhttps://datahacker.rs/008-machine-learning-multiclass-classification-and-softmax-function/\n\n\nCan you think of any examples of algorithms you encounter in your everyday life that solve classification problems?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Problem Classes in ML"
    ]
  },
  {
    "objectID": "week2_2.html#regression",
    "href": "week2_2.html#regression",
    "title": "Problem Classes in ML",
    "section": "Regression",
    "text": "Regression\n\nIn regression problems we are typically concerned with predicting a real-valued number for each item.\nFor example, we might be interested in predicting stock prices, or how .\nstressed out someone is.\nNotes: The penalty for prediction errors depends on the magnitude of the difference between true and predicted values, unlike classification where categories are discrete and there is often no notion of distance between various categories.\n\n\n\nhttps://builtin.com/data-science/regression-machine-learning\n\n\n\nCan you think of any examples of algorithms you encounter in your everyday life that solve regression-type problems?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Problem Classes in ML"
    ]
  },
  {
    "objectID": "week2_2.html#ranking",
    "href": "week2_2.html#ranking",
    "title": "Problem Classes in ML",
    "section": "Ranking",
    "text": "Ranking\n\nWith ranking problems we are often tasked with ordering items according to a specific criterion.\nA well-known example of a ranking algorithm is Google’s PageRank algorithm.\nNotes: Ranking problems focus on relative order rather than exact category or numeric value.\n\n\n\n\nhttps://towardsdatascience.com/wp-content/uploads/2023/08/1ZFmd2Q-G95ArY93od20Adw.png\n\n\nCan you think of any examples of algorithms you encounter in your everyday life that solve ranking problems?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Problem Classes in ML"
    ]
  },
  {
    "objectID": "week2_2.html#clustering",
    "href": "week2_2.html#clustering",
    "title": "Problem Classes in ML",
    "section": "Clustering",
    "text": "Clustering\n\nIn clustering problems we are typically looking topartition items into similar groups or regions.\nFor example, in social network analysis we are interested in identifying communities within large groups of people\nNotes: Clustering is often applied to very large datasets to reveal underlying structure.\n\n\n\n\nhttps://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png\n\n\nHow do the classification and clustering problems discussed thus far differ?\nCan you think of any examples of algorithms you encounter in your everyday life that solve clustering problems?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Problem Classes in ML"
    ]
  },
  {
    "objectID": "week2_2.html#dimensionality-reduction",
    "href": "week2_2.html#dimensionality-reduction",
    "title": "Problem Classes in ML",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nWhen looking to solve dimension reduction problems we are typically interested in transforming high-dimensional data into a lower-dimensional representation while preserving important properties.\nCommon examples in psychology include identifying constructs in survey data or scales.\nNotes: Dimension reduction is also useful for feature extraction, noise reduction, and speeding up downstream learning tasks.\n\n\n\n\nhttps://www.sthda.com/english/sthda-upload/figures/principal-component-methods/006-principal-component-analysis-pca-variable-cos2-corrplot-1.png\n\n\nCan you think of any examples of algorithms you encounter in your everyday life that solve dimension reduction problems?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Problem Classes in ML"
    ]
  },
  {
    "objectID": "week2_1.html",
    "href": "week2_1.html",
    "title": "Important Distinctions",
    "section": "",
    "text": "The vast amount of jargon one encounters when first diving into the machine learning literature is a common source of confusion for new learners. Many ML terms are borrowed from statistics, computer science, or everyday language, but they can carry subtly or even radically different meanings in ML contexts.\nWith the following overview I will provide a high-level overview of some common terms used in machine learning, and try to highlight the differences between concepts that may seem similar, but often represent distinct ideas.\nTwo important distinctions:\nArtificial Intelligence (AI) and Machine Learning (ML) are related but distinct concepts in computer science and data analysis.\nML approaches rely heavily on accurate and efficient prediction algorithms.\nSo, what exactly are algorithms?\nAn algorithm is a step-by-step, well-defined procedure for solving a problem or completing a task.\nIn computing and machine learning, algorithms are generally a finite sequence of instructions that takes some input, follows a set of rules, and produces an output.\nA model in machine learning is the learned representation of patterns in data, produced by applying a learning algorithm to a dataset. It is what we use to make predictions, classify new examples, or infer relationships.\nUnderstanding what algorithm to choose for a specific problem or application is often difficult. In this class we will devote a lot of time on how to make these decisions, and communicate the results of an analysis. That said, we often have minimal knowledge of the problem or data at hand when we first approach an applied problem, and it is difficult to know which ML method will perform best. This idea is generally known as the no free lunch theorem\nAn algorithm is just a set of step-by-step instructions to solve a problem. Machine learning algorithms are no different—they’re just systematic ways of finding patterns in data. Let’s explore what that means.\nIn groups of 3–4, imagine you are writing an algorithm for a simple real-world problem:\nEach group should discuss (and prepare to share):",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "week2_1.html#artificial-intelligence-ai",
    "href": "week2_1.html#artificial-intelligence-ai",
    "title": "Important Distinctions",
    "section": "Artificial Intelligence (AI)",
    "text": "Artificial Intelligence (AI)\n\nAI is the broad field of creating systems that can perform tasks that normally require human intelligence.\nTypically, the goal of AI is to create machines that can simulate intelligent behavior, whether or not they learn from data.\nCommon Examples of AI include:\n\nLarge Language Models\n\n\nCan you think of any examples of AI you encounter in your everyday life?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "week2_1.html#machine-learning-ml",
    "href": "week2_1.html#machine-learning-ml",
    "title": "Important Distinctions",
    "section": "Machine Learning (ML)",
    "text": "Machine Learning (ML)\n\nML is a branch of AI focused on systems that learn patterns from data and improve automatically from experience.\nWhen doing ML we are generally interested in creating models that generalize from data to make accurate predictions on unseen inputs.\nCommon use cases for ML in everyday life include:\n\nClutter or spam email detection\n\n\nCan you think of any examples of ML you encounter in your everyday life?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "week2_1.html#differences-between-ai-and-ml",
    "href": "week2_1.html#differences-between-ai-and-ml",
    "title": "Important Distinctions",
    "section": "Differences Between AI and ML",
    "text": "Differences Between AI and ML\n\n\n\n\n\n\n\n\n\n\nAspect\nArtificial Intelligence (AI)\nMachine Learning (ML)\n\n\n\n\nFocus\nSimulating intelligent behavior\nLearning patterns from data\n\n\nGoal\nBroader human-like intelligence\nSpecific predictive or decision-making tasks\n\n\nExamples\nChess engines, self-driving cars, expert systems\nRegression, neural networks, clustering\n\n\n\nBroadly speaking, ML is a branch of AI focused on training models to recognize patterns and make predictions using algorithms. AI encompasses a broader set of techniques, some of which do not involve learning from data at all.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "week2_1.html#characteristics-of-an-algorithm",
    "href": "week2_1.html#characteristics-of-an-algorithm",
    "title": "Important Distinctions",
    "section": "Characteristics of an Algorithm",
    "text": "Characteristics of an Algorithm\n\nInput – Data the algorithm operates on\nOutput – The result produced after execution\nFiniteness – Must finish in a finite number of steps\nDefiniteness – Each step is clear and unambiguous\nEffectiveness – Each operation can actually be carried out",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "week2_1.html#algorithms-in-machine-learning",
    "href": "week2_1.html#algorithms-in-machine-learning",
    "title": "Important Distinctions",
    "section": "Algorithms in Machine Learning",
    "text": "Algorithms in Machine Learning\n\nIn ML, an algorithm is the procedure used to train a model from data.\nExample: Linear regression algorithm finds the best-fit line by minimizing error.\nExample: Decision tree algorithm splits data into branches by checking features step by step.\n\nOne can think of an algorithm as the recipe one follows when cooking a meal. The ingredients of the dish are analogous to the input data, and the finished dish is equivalent to the model.\n\n\n\nhttps://xkcd.com/1667/\n\n\nSo, how does an algorithm differ from a model? What is a model in the context of ML?",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "week2_1.html#definition",
    "href": "week2_1.html#definition",
    "title": "Important Distinctions",
    "section": "Definition",
    "text": "Definition\nA model is the outcome of training a machine learning algorithm on data.It encapsulates the patterns, relationships, or structure discovered in the training data.\n\nInput: Features from the training data\n\nProcess: Algorithm (e.g., linear regression, decision tree, neural network)\n\nOutput: Parameters, structure, or rules that allow prediction",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "week2_1.html#examples",
    "href": "week2_1.html#examples",
    "title": "Important Distinctions",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\n\n\nAlgorithm\nResulting Model\nWhat It Represents\n\n\n\n\nLinear Regression\nA line (y = mx + b)\nRelationship between input and output variables\n\n\nDecision Tree\nTree of splits\nHow features split to predict classes or values\n\n\nNeural Network\nLayers of neurons & weights\nComplex non-linear mappings between inputs and outputs\n\n\nk-Means Clustering\nCluster centroids\nGrouping of data points into clusters",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "week2_1.html#things-to-remember",
    "href": "week2_1.html#things-to-remember",
    "title": "Important Distinctions",
    "section": "Things to Remember",
    "text": "Things to Remember\n\nThe algorithm is the procedure for learning\n\nThe model is the trained artifact used for prediction or inference\n\nDifferent algorithms can produce different models from the same data\n\nA model generalizes patterns from training data to unseen data\nAlgorithm = recipe (instructions for learning)\n\nModel = finished dish (learned representation ready to use)\n\nThe model is the end product of learning — the part that actually “knows” something about the data and can be used to make predictions. In ML: Data + Algorithm → Model → Predictions.",
    "crumbs": [
      "Introduction to Machine Learning",
      "Important Distinctions"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "PSYC559: APPLIED MACHINE LEARNING IN PSYCHOLOGY",
    "section": "",
    "text": "Welcome to Applied Machine Learning in Psychology.",
    "crumbs": [
      "Table of Contents"
    ]
  },
  {
    "objectID": "introduction.html#the-syllabus",
    "href": "introduction.html#the-syllabus",
    "title": "PSYC559: APPLIED MACHINE LEARNING IN PSYCHOLOGY",
    "section": "The Syllabus",
    "text": "The Syllabus\nStudents may review the syllabus on Canvas.",
    "crumbs": [
      "Table of Contents"
    ]
  }
]