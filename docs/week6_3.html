<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>K-Means Cluster Analysis – PSYC559: Applied Machine Learning in Psychology</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-121a38a6e2c75e451ef209d5f681333d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week6_1.html">Dimension Reduction</a></li><li class="breadcrumb-item"><a href="./week6_3.html">K-Means Cluster Analysis</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">PSYC559: Applied Machine Learning in Psychology</a> 
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.qmd" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Table of Contents</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction to R</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic R Programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1b.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">R Packages</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reading in Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Describing Data Numerically</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Describing Data Visually</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction to Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Important Terms and Distinctions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Problem Classes in ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bias and Variance</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Feature Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_5a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_5b.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_5c.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Missing Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_5d.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Feature Filtering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_5e.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Numeric Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_5f.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Categorical Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_5g.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workflow</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Regression Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regularized Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Tree Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bagging</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Forests</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gradient Boosting</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Dimension Reduction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principal Components Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hierarchical Cluster Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_3.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">K-Means Cluster Analysis</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#a-brief-history-of-k-means" id="toc-a-brief-history-of-k-means" class="nav-link" data-scroll-target="#a-brief-history-of-k-means">A Brief History of K-Means</a></li>
  <li><a href="#early-origins" id="toc-early-origins" class="nav-link" data-scroll-target="#early-origins">Early Origins</a></li>
  <li><a href="#formalization-by-lloyd-1957-1982" id="toc-formalization-by-lloyd-1957-1982" class="nav-link" data-scroll-target="#formalization-by-lloyd-1957-1982">Formalization by Lloyd (1957, 1982)</a></li>
  <li><a href="#parallel-development-macqueen-1967" id="toc-parallel-development-macqueen-1967" class="nav-link" data-scroll-target="#parallel-development-macqueen-1967">Parallel Development: MacQueen (1967)</a></li>
  <li><a href="#modern-usage" id="toc-modern-usage" class="nav-link" data-scroll-target="#modern-usage">Modern Usage</a></li>
  <li><a href="#a-brief-history-of-dbscan" id="toc-a-brief-history-of-dbscan" class="nav-link" data-scroll-target="#a-brief-history-of-dbscan">A Brief History of DBSCAN</a></li>
  <li><a href="#early-origins-1" id="toc-early-origins-1" class="nav-link" data-scroll-target="#early-origins-1">Early Origins</a></li>
  <li><a href="#origins-and-motivation" id="toc-origins-and-motivation" class="nav-link" data-scroll-target="#origins-and-motivation">Origins and Motivation</a></li>
  <li><a href="#innovations" id="toc-innovations" class="nav-link" data-scroll-target="#innovations">Innovations</a></li>
  <li><a href="#modern-usage-1" id="toc-modern-usage-1" class="nav-link" data-scroll-target="#modern-usage-1">Modern Usage</a></li>
  <li><a href="#k-means-clustering" id="toc-k-means-clustering" class="nav-link" data-scroll-target="#k-means-clustering">K-Means Clustering</a></li>
  <li><a href="#defining-a-cluster" id="toc-defining-a-cluster" class="nav-link" data-scroll-target="#defining-a-cluster">Defining a Cluster</a></li>
  <li><a href="#k-means-algorithm" id="toc-k-means-algorithm" class="nav-link" data-scroll-target="#k-means-algorithm">K-means Algorithm</a></li>
  <li><a href="#k-means-algorithm-1" id="toc-k-means-algorithm-1" class="nav-link" data-scroll-target="#k-means-algorithm-1">K-Means Algorithm</a></li>
  <li><a href="#example-of-algorithm" id="toc-example-of-algorithm" class="nav-link" data-scroll-target="#example-of-algorithm">Example of Algorithm</a></li>
  <li><a href="#sensitivity-to-starting-values" id="toc-sensitivity-to-starting-values" class="nav-link" data-scroll-target="#sensitivity-to-starting-values">Sensitivity to Starting Values</a></li>
  <li><a href="#local-optimum" id="toc-local-optimum" class="nav-link" data-scroll-target="#local-optimum">Local Optimum</a></li>
  <li><a href="#choosing-k" id="toc-choosing-k" class="nav-link" data-scroll-target="#choosing-k">Choosing K</a></li>
  <li><a href="#how-to-choose-k" id="toc-how-to-choose-k" class="nav-link" data-scroll-target="#how-to-choose-k">How to Choose K?</a></li>
  <li><a href="#dbscan" id="toc-dbscan" class="nav-link" data-scroll-target="#dbscan">DBSCAN</a></li>
  <li><a href="#example-of-dbscan" id="toc-example-of-dbscan" class="nav-link" data-scroll-target="#example-of-dbscan">Example of DBSCAN</a></li>
  <li><a href="#issues-in-clustering" id="toc-issues-in-clustering" class="nav-link" data-scroll-target="#issues-in-clustering">Issues in Clustering</a></li>
  <li><a href="#some-recommendations" id="toc-some-recommendations" class="nav-link" data-scroll-target="#some-recommendations">Some Recommendations</a></li>
  <li><a href="#example-clustering-digits" id="toc-example-clustering-digits" class="nav-link" data-scroll-target="#example-clustering-digits">Example: Clustering Digits</a></li>
  <li><a href="#example-esm-data" id="toc-example-esm-data" class="nav-link" data-scroll-target="#example-esm-data">Example: ESM Data</a></li>
  <li><a href="#k-means" id="toc-k-means" class="nav-link" data-scroll-target="#k-means">K-Means</a></li>
  <li><a href="#evaluation-of-clustering-quality" id="toc-evaluation-of-clustering-quality" class="nav-link" data-scroll-target="#evaluation-of-clustering-quality">Evaluation of Clustering Quality</a></li>
  <li><a href="#obtaining-a-stable-solution" id="toc-obtaining-a-stable-solution" class="nav-link" data-scroll-target="#obtaining-a-stable-solution">Obtaining a Stable Solution</a></li>
  <li><a href="#post-clustering-analyses" id="toc-post-clustering-analyses" class="nav-link" data-scroll-target="#post-clustering-analyses">Post-Clustering Analyses</a></li>
  <li><a href="#describing-clusters" id="toc-describing-clusters" class="nav-link" data-scroll-target="#describing-clusters">Describing Clusters</a></li>
  <li><a href="#analyzing-clusters" id="toc-analyzing-clusters" class="nav-link" data-scroll-target="#analyzing-clusters">Analyzing Clusters</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week6_1.html">Dimension Reduction</a></li><li class="breadcrumb-item"><a href="./week6_3.html">K-Means Cluster Analysis</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">K-Means Cluster Analysis</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level1" style="color: yellow">
<h1>Introduction</h1>
</section>
<p>This section of the book cover K-Means Clustering and DBSCAN clustering methods.</p>
<section id="a-brief-history-of-k-means" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="a-brief-history-of-k-means">A Brief History of K-Means</h2>
</section>
<section id="early-origins" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="early-origins">Early Origins</h3>
</section>
<p>The origins of <strong>K-Means clustering</strong> trace back to the mid-20th century, with multiple independent discoveries across disciplines. The basic idea—partitioning data into <em>k</em> groups to minimize within-group variance—was first mentioned by <strong>Hugo Steinhaus (1956)</strong>, who described a method for dividing points into clusters based on proximity.</p>
<section id="formalization-by-lloyd-1957-1982" class="level2" style="color: lightyellow">
<h2 class="anchored" data-anchor-id="formalization-by-lloyd-1957-1982">Formalization by Lloyd (1957, 1982)</h2>
</section>
<p>The algorithm most people associate with K-Means was first introduced by Stuart Lloyd in a 1957 Bell Labs internal technical report titled “Least Squares Quantization in PCM”. Although unpublished for decades, his work was rediscovered and officially published in 1982.</p>
<p>Lloyd’s version of K-Means introduced the iterative refinement procedure:</p>
<ol type="1">
<li>Assign each point to the nearest cluster centroid.</li>
<li>Recompute each centroid as the mean of its assigned points.</li>
<li>Repeat until assignments no longer change.</li>
</ol>
<p>This became the foundation for modern K-Means implementations.</p>
<section id="parallel-development-macqueen-1967" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="parallel-development-macqueen-1967">Parallel Development: MacQueen (1967)</h3>
</section>
<p>Around the same time, James MacQueen (1967) independently proposed a similar algorithm in his paper “Some Methods for Classification and Analysis of Multivariate Observations.” MacQueen formalized the term “K-Means” and emphasized its use in statistical pattern recognition and data analysis.</p>
<section id="modern-usage" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="modern-usage">Modern Usage</h3>
</section>
<p>Today, K-Means is one of the most widely used unsupervised learning algorithms in data science, statistics, and psychology. Its simplicity, speed, and interpretability have made it a standard for:</p>
<ul>
<li>Market segmentation<br>
</li>
<li>Image compression<br>
</li>
<li>Behavioral clustering<br>
</li>
<li>High-dimensional data exploration</li>
</ul>
<p>While its assumptions (spherical clusters, equal variance) limit its use in some contexts, K-Means remains foundational in both machine learning and psychological data analysis.</p>
<section id="a-brief-history-of-dbscan" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="a-brief-history-of-dbscan">A Brief History of DBSCAN</h2>
</section>
<p>DBSCAN (Density-Based Spatial Clustering of Applications with Noise) groups together points that are closely packed based on density, while marking isolated points as outliers. Unlike K-Means, it does not require specifying the number of clusters in advance and can find clusters of arbitrary shape.</p>
<section id="early-origins-1" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="early-origins-1">Early Origins</h3>
</section>
<p>DBSCAN was introduced in 1996 by Ester, Kriegel, Sander, Xu in their paper “A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.”</p>
<section id="origins-and-motivation" class="level2" style="color: lightyellow">
<h2 class="anchored" data-anchor-id="origins-and-motivation">Origins and Motivation</h2>
</section>
<p>DBSCAN emerged from the field of spatial data mining, where traditional clustering algorithms like K-Means struggled with:</p>
<ul>
<li>Clusters of arbitrary shape</li>
<li>Outliers (noise points)</li>
<li>Non-uniform cluster density</li>
</ul>
<p>The authors’ goal was to define clusters as areas of high point density, rather than assuming spherical shapes or specifying the number of clusters in advance.</p>
<section id="innovations" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="innovations">Innovations</h3>
</section>
<p>DBSCAN introduced two important parameters:</p>
<ul>
<li><strong>ε (epsilon):</strong> The neighborhood radius<br>
</li>
<li><strong>MinPts:</strong> The minimum number of points required to form a dense region</li>
</ul>
<p>The algorithm identifies <strong>core points</strong> (dense regions), <strong>border points</strong>, and <strong>noise points</strong>, expanding clusters outward from dense cores. This approach made DBSCAN robust to noise and capable of detecting clusters with irregular boundaries.</p>
<section id="modern-usage-1" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="modern-usage-1">Modern Usage</h3>
</section>
<p>Today, DBSCAN is widely used in: - Geospatial analysis - Anomaly detection - Pattern recognition - Psychological and behavioral clustering (where outliers and irregular group shapes are common)</p>
<section id="k-means-clustering" class="level1" style="color: yellow">
<h1>K-Means Clustering</h1>
</section>
<p>Clustering requires a way to measure how similar or different observations are, typically by computing a distance or dissimilarity matrix.</p>
<p>As we discussed previously, the chosen distance measure is crucial because it determines how similarity is quantified and influences the resulting cluster shapes and sizes.</p>
<p>Common distance measures include Euclidean and Manhattan distances, but alternatives like correlation-based, Gower, or cosine distances are often used depending on the data type and context.</p>
<section id="defining-a-cluster" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="defining-a-cluster">Defining a Cluster</h2>
</section>
<p>The central goal of K-means clustering is to form clusters that minimize the total within-cluster variation. Clusters are groups of observations, for example, people.</p>
<p>Several algorithms exist for this purpose, with the standard being the Hartigan-Wong algorithm (Hartigan and Wong, 1979).</p>
<p>A good clustering solution is one for which the within-cluster variation is as small as possible</p>
<p>This method defines the total within-cluster variation as the sum of the squared Euclidean distances between each observation and its corresponding cluster centroid:</p>
<p><span class="math display">\[
W(C_k) = \sum_{x_i \in C_k} (x_i - \mu_k)^2
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(x_i\)</span> is an observation belonging to cluster <span class="math inline">\(C_k\)</span></li>
<li><span class="math inline">\(\mu_k\)</span> is the mean (centroid) of all points assigned to cluster <span class="math inline">\(C_k\)</span></li>
</ul>
<p>Each observation (<span class="math inline">\(x_i\)</span>) is assigned to a given cluster such that the sum of squared (SS) distances of each observation to their assigned cluster centers (<span class="math inline">\(\mu_k\)</span>) is minimized.</p>
<p>To make this concrete, let’s define within cluster variation using the squared Euclidian distance (the most commonly used metric)</p>
<p><span class="math display">\[
W(C_{k}) = \frac{1}{|C_k|}\sum_{i,i'\in C_k}\sum_{j=1}^{p}(x_{ij}-x_{i'j})^2
\]</span></p>
<p>Furthermore, the total within-cluster variation, or sum of squares within clusters, is defined as:</p>
<p><span class="math display">\[
SS_{\text{within}} = \sum_{k=1}^{K} W(C_k) = \sum_{k=1}^{K} \sum_{x_i \in C_k} (x_i - \mu_k)^2
\]</span></p>
<p>This measure, <span class="math inline">\(SS_{\text{within}}\)</span>, quantifies the compactness or “goodness” of the resulting clusters. A smaller value of <span class="math inline">\(SS_{\text{within}}\)</span> indicates tighter, more cohesive clusters.</p>
<p><img src="imgs/cluster_sep.png" class="img-fluid"></p>
<section id="k-means-algorithm" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="k-means-algorithm">K-means Algorithm</h2>
</section>
<p>The K-means algorithm will assign each observation to exactly one of the <span class="math inline">\(K\)</span> clusters.</p>
<section id="k-means-algorithm-1" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="k-means-algorithm-1">K-Means Algorithm</h3>
</section>
<ol type="1">
<li>Specify <span class="math inline">\(K\)</span>, the number of clusters</li>
<li>Randomly select <span class="math inline">\(K\)</span> initial cluster means (centroids)</li>
<li>Assignment step: Assign each observation to the cluster whose centroid is closest (where closest is defined using squared Euclidean distance)</li>
<li>Adjustment step:Compute the new cluster means (centroids).</li>
<li>Iterate the Assignment and Update steps until the assignments no longer change.</li>
</ol>
<section id="example-of-algorithm" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="example-of-algorithm">Example of Algorithm</h3>
</section>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans2.png" class="img-fluid figure-img"></p>
<figcaption>K-means Example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans4.png" class="img-fluid figure-img"></p>
<figcaption>K-means Example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans5.png" class="img-fluid figure-img"></p>
<figcaption>K-means Example</figcaption>
</figure>
</div>
<p><img src="imgs/kmeans6.png" class="img-fluid" alt="K-means Example"> Here, we establish a new centroid (X) based on the means of the current assignment Then do the assignment again by cacluting the closeness to the new centroid,</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans7.png" class="img-fluid figure-img"></p>
<figcaption>K-means Example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans8.png" class="img-fluid figure-img"></p>
<figcaption>K-means Example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans9.png" class="img-fluid figure-img"></p>
<figcaption>K-means Example</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans10.png" class="img-fluid figure-img"></p>
<figcaption>K-means Example</figcaption>
</figure>
</div>
<section id="sensitivity-to-starting-values" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="sensitivity-to-starting-values">Sensitivity to Starting Values</h3>
</section>
<p>The K-means algorithm is sensitive to the initial random assignment of cluster centroids.</p>
<p><img src="imgs/kmeans11.png" class="img-fluid" alt="K-means Snapshot"> Randomness of the initial choice for the starting point. We might end up with different solutions when we have different starting points.</p>
<p>Now, let’s take a look with various random starting points.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans12.png" class="img-fluid figure-img"></p>
<figcaption>K-means Snapshot</figcaption>
</figure>
</div>
<p>We ended up with three clusters, but the random start value influenced, above the variance is printed, there are 4 identical solutions <span class="math inline">\(235.8\)</span> but different order (label switching).</p>
<section id="local-optimum" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="local-optimum">Local Optimum</h3>
</section>
<p>The K-Means algorithm finds a local rather than a global optimum. This means results obtained will depend on the initial (random) cluster assignment of each observation</p>
<p>It is important to run the algorithm multiple times from different random starting values and then select the best solution. Here, by best, we mean the minimum within cluster variance.</p>
<section id="choosing-k" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="choosing-k">Choosing K</h2>
</section>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans13.png" class="img-fluid figure-img"></p>
<figcaption>Choosing K?</figcaption>
</figure>
</div>
<section id="how-to-choose-k" class="level3" style="color: lightyellow">
<h3 class="anchored" data-anchor-id="how-to-choose-k">How to Choose K?</h3>
</section>
<p>You want to maximize data reduction while making sure that you have good accuracy in terms of cluster memberships.</p>
<p>Some possibilities for choosing <span class="math inline">\(K\)</span>:</p>
<ul>
<li>Elbow method (see also within and between sum of squares in the R script)</li>
<li>Information criterion approach (AIC, BIC, DIC)</li>
<li>Two-step approach – using the dendogram from hierarchical clustering</li>
<li>Using the Silhouette coefficient (see next)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans14.png" class="img-fluid figure-img"></p>
<figcaption>Elbow Method</figcaption>
</figure>
</div>
<p><strong>Silhouette Coefficient</strong></p>
<p><img src="imgs/kmeans15.jpg" class="img-fluid" alt="Silhouette Coefficient"> The silhouette coefficient is one such measure. It works as follows:</p>
<p>For each point <span class="math inline">\(p\)</span>, first find the average distance between p and all other points in the same cluster (this is a measure of cohesion, call it <span class="math inline">\(a\)</span>).</p>
<p>Then find the average distance between <span class="math inline">\(p\)</span> and all points in the nearest cluster (this is a measure of separation from the closest other cluster, call it <span class="math inline">\(b\)</span>).</p>
<p>The silhouette coefficient for <span class="math inline">\(p\)</span> is defined as the difference between <span class="math inline">\(b\)</span> and <span class="math inline">\(a\)</span> divided by the greater of the two (<span class="math inline">\(max(a,b)\)</span>).</p>
<p>We evaluate the cluster coefficient of each point and from this we can obtain the ‘overall’ average cluster coefficient.</p>
<p>Intuitively, we are trying to measure the space between clusters. If cluster cohesion is good (<span class="math inline">\(a\)</span> is small) and cluster separation is good (<span class="math inline">\(b\)</span> is large), the numerator will be large, etc.</p>
<p>The silhouette plot shows the that the silhouette coefficient was highest when <span class="math inline">\(k = 3\)</span>, suggesting that’s the optimal number of clusters. In this example we are lucky to be able to visualize the data and we might agree that indeed, three clusters best captures the segmentation of this data set.</p>
<p>If we were unable to visualize the data, perhaps because of higher dimensionality, a silhouette plot would still give us a suggestion.</p>
<section id="dbscan" class="level1" style="color: yellow">
<h1>DBSCAN</h1>
</section>
<p>Another method to consider is Density-based spatial clustering of applications with noise (DBSCAN).</p>
<p>DBSCAN is a powerful, widely used method – great with identifying clusters of arbitrary shape clusters together points that are closely packed together (high density regions), and identifies outliers (not part of any clusters) as points whose neighbors are far away (low-density regions).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans16.png" class="img-fluid figure-img"></p>
<figcaption>Algorithm Comparison</figcaption>
</figure>
</div>
<section id="example-of-dbscan" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="example-of-dbscan">Example of DBSCAN</h2>
</section>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans17.png" class="img-fluid figure-img"></p>
<figcaption>DBSCAN Example</figcaption>
</figure>
</div>
<p><strong>Eps</strong>: You have to choose this value. Recommended to be smallish and based on domain knowledge. Eps defines the size and borders of each neighborhood. The Eps (must be bigger than 0) is a radius. The neighborhood of point <span class="math inline">\(p\)</span> called the Eps-neighborhood of <span class="math inline">\(p\)</span>, is the ball with radius Eps around point <span class="math inline">\(p\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/kmeans18.png" class="img-fluid figure-img"></p>
<figcaption>DBSCAN Example</figcaption>
</figure>
</div>
<p><strong>MinPts</strong>: You have to choose this value. Recommended to be twice the number of dimensions in your dataset.</p>
<p>MinPts is the density threshold. If a neighborhood includes at least MinPts points, it will be considered as a dense region. Alternatively, a point will be considered as dense if there are at least the value of MinPts points in its Eps-neighborhood. These dense points are called core points.</p>
<p>Point <span class="math inline">\(p\)</span> is a core point because the size of its Eps-neighborhood is 12 and MinPts is 5. Point <span class="math inline">\(q\)</span>, on the other hand, won’t be a core point because its Eps-neighborhood is 4, smaller than MinPts.</p>
<p>A border point has Eps-neighborhood that contains less than MinPts points (so it’s not a core point), but it belongs to the Eps-neighborhood of another core point.</p>
<p>If a point isn’t a core point and isn’t a border point, it’s a noise point or an outlier.</p>
<p>In the figure below we can see that point <span class="math inline">\(x\)</span> is a core point, because it has more than <span class="math inline">\(11\)</span> points in its Eps-neighborhood. Point <span class="math inline">\(y\)</span> isn’t a core point because it has less than <span class="math inline">\(11\)</span> points in its Eps-neighborhood, but because it belongs to the Eps-neighborhood of point <span class="math inline">\(x\)</span>, and point <span class="math inline">\(x\)</span> is a core point, point <span class="math inline">\(y\)</span> is a border point. We can easily see that point <span class="math inline">\(z\)</span> isn’t a core point. It belongs to the Eps-neighborhood of point <span class="math inline">\(y\)</span>, but point <span class="math inline">\(y\)</span> isn’t a core point, therefore point <span class="math inline">\(z\)</span> is a noise point.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs/dbscan1.png" class="img-fluid figure-img"></p>
<figcaption><a href="https://towardsdatascience.com/a-practical-guide-to-dbscan-method-d4ec5ab2bc99" class="uri">https://towardsdatascience.com/a-practical-guide-to-dbscan-method-d4ec5ab2bc99</a></figcaption>
</figure>
</div>
<p><img src="imgs/kmeans19.png" class="img-fluid" alt="DBSCAN Example"> Note, the assumption here is that we sampled well, like there are really not a lot of people around the outlier.</p>
<p>A wonderful illustrated description of the DBSCAN algorithm can be found at: <a href="https://towardsdatascience.com/a-practical-guide-to-dbscan-method-d4ec5ab2bc99" class="uri">https://towardsdatascience.com/a-practical-guide-to-dbscan-method-d4ec5ab2bc99</a></p>
<section id="issues-in-clustering" class="level1" style="color: yellow">
<h1>Issues in Clustering</h1>
</section>
<ul>
<li>Determining the number of clusters to retain</li>
<li>Cross-validation of clusters and cluster sizes</li>
<li>All or none decision process (Either in or out of a cluster)</li>
<li>What to do with observations that really don’t belong in any cluster</li>
<li>Consequences of choices among linkage, dissimilarity measure, cutting dendrogram</li>
</ul>
<section id="some-recommendations" class="level1" style="color: yellow">
<h1>Some Recommendations</h1>
</section>
<p>Perform clustering with different choices of parameters, and look at the full set of results in order to see what patterns consistently emerge</p>
<p>Since clustering can be non-robust, recommend to cluster subsets of the data and evaluate robustness of the clusters obtained</p>
<p>Most importantly, must be careful about how the results of a clustering analysis are reported.</p>
<p>Results should not be taken as the absolute truth about a data set.</p>
<p>Instead, results often constitute a starting point for the development of a scientific hypothesis and further study, preferably on an independent data set</p>
<section id="example-clustering-digits" class="level1" style="color: yellow">
<h1>Example: Clustering Digits</h1>
</section>
<p>Let’s illustrate an example by performing k-means clustering on the MNIST pixel features and see if we can identify unique clusters of digits without using the response variable.</p>
<p>Here, we declare k=10 only because we already know there are 10 unique digits represented in the data. We also use 10 random starts (<code>nstart = 10</code>).</p>
<p>The output of our model contains many of the metrics we’ve already discussed such as total within-cluster variation (<code>withinss</code>), total within-cluster sum of squares (<code>tot.withinss</code>), the size of each cluster (<code>size</code>), and the iteration out of our 10 random starts used (<code>iter</code>). It also includes the cluster each observation is assigned to and the centers of each cluster.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dslabs)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>mnist <span class="ot">&lt;-</span> dslabs<span class="sc">::</span><span class="fu">read_mnist</span>()</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">"https://koalaverse.github.io/homlr/data/my_basket.csv"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>my_basket <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(url)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>features <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>images</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(features)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> int [1:60000, 1:784] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
</div>
<p>Now we can cluster the features using K-means and the <code>kmeans()</code> function in R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use k-means model with 10 centers and 10 random starts</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>mnist_clustering <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(features, <span class="at">centers =</span> <span class="dv">10</span>, <span class="at">nstart =</span> <span class="dv">10</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print contents of the model output</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(mnist_clustering)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>List of 9
 $ cluster     : int [1:60000] 8 7 6 4 9 1 5 8 5 9 ...
 $ centers     : num [1:10, 1:784] 0 0 0 0 0 0 0 0 0 0 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:10] "1" "2" "3" "4" ...
  .. ..$ : NULL
 $ totss       : num 2.06e+11
 $ withinss    : num [1:10] 1.51e+10 2.19e+10 1.58e+10 1.04e+10 9.08e+09 ...
 $ tot.withinss: num 1.53e+11
 $ betweenss   : num 5.27e+10
 $ size        : int [1:10] 4681 7447 5717 5620 5967 8918 3176 6544 8837 3093
 $ iter        : int 8
 $ ifault      : int 0
 - attr(*, "class")= chr "kmeans"</code></pre>
</div>
</div>
<p>The centers output is a <code>10x784</code> matrix. This matrix contains the average value of each of the 784 features for the 10 clusters.</p>
<p>We can plot this as in Figure 20.5 which shows us what the typical digit is in each cluster. We clearly see recognizable digits even though k-means had no insight into the response variable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract cluster centers</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>mnist_centers <span class="ot">&lt;-</span> mnist_clustering<span class="sc">$</span>centers</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot typical cluster digits</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">matrix</span>(<span class="fu">seq_len</span>(<span class="fu">nrow</span>(mnist_centers)), <span class="dv">2</span>, <span class="dv">5</span>, <span class="at">byrow =</span> <span class="cn">FALSE</span>))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">nrow</span>(mnist_centers))) {</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">image</span>(<span class="fu">matrix</span>(mnist_centers[i, ], <span class="dv">28</span>, <span class="dv">28</span>)[, <span class="dv">28</span><span class="sc">:</span><span class="dv">1</span>], </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="fu">gray.colors</span>(<span class="dv">12</span>, <span class="at">rev =</span> <span class="cn">TRUE</span>), <span class="at">xaxt=</span><span class="st">"n"</span>, <span class="at">yaxt=</span><span class="st">"n"</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week6_3_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Since we also know the truth here we can take a look at the accuracy of our clustering by comparing the cluster assignments to the actual digit labels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mode function</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>mode_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(x){  </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which.max</span>(<span class="fu">tabulate</span>(x))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>mnist_comparison <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">cluster =</span> mnist_clustering<span class="sc">$</span>cluster,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">actual =</span> mnist<span class="sc">$</span>train<span class="sc">$</span>labels</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(cluster) <span class="sc">%&gt;%</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mode =</span> <span class="fu">mode_fun</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_all</span>(factor, <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix and plot results</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>yardstick<span class="sc">::</span><span class="fu">conf_mat</span>(</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  mnist_comparison, </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> actual, </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> mode</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="at">type =</span> <span class="st">'heatmap'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week6_3_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>When clustering the MNIST data, the number of clusters we specified was based on prior knowledge of the data. However, often we do not have this kind of a priori information and the reason we are performing cluster analysis is to identify what clusters may exist. So how do we go about determining the right number of k? Let’s examine this in more detail.</p>
<section id="example-esm-data" class="level2" style="color: yellow">
<h2 class="anchored" data-anchor-id="example-esm-data">Example: ESM Data</h2>
</section>
<p>Again, let’s use the experience sampling data sets, but treats these data as though they are cross-sectional. Getting the data and doing a bit of data management (new id variable)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#set filepath for data file</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>filepath <span class="ot">&lt;-</span> <span class="st">"https://quantdev.ssri.psu.edu/sites/qdev/files/AMIBbrief_raw_daily1.csv"</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">#read in the .csv file using the url() function</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>daily <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file=</span><span class="fu">url</span>(filepath),<span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#clean-up of variable names so that they are all lowercase</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>var.names.daily <span class="ot">&lt;-</span> <span class="fu">tolower</span>(<span class="fu">colnames</span>(daily))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(daily)<span class="ot">&lt;-</span>var.names.daily</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#creating a new "id" variable</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">#(we had repeated measures nested in people, now they all get different ids)</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>daily<span class="sc">$</span>id <span class="ot">&lt;-</span> daily<span class="sc">$</span>id<span class="sc">*</span><span class="dv">10</span><span class="sc">+</span>daily<span class="sc">$</span>day</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(daily)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "id"      "day"     "date"    "slphrs"  "weath"   "lteq"    "pss"    
 [8] "se"      "swls"    "evalday" "posaff"  "negaff"  "temp"    "hum"    
[15] "wind"    "bar"     "prec"   </code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#reducing down to variable set</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>daily <span class="ot">&lt;-</span> daily[ ,<span class="fu">c</span>(<span class="st">"id"</span>,<span class="st">"slphrs"</span>,<span class="st">"weath"</span>,<span class="st">"lteq"</span>,<span class="st">"pss"</span>,<span class="st">"se"</span>,<span class="st">"swls"</span>,<span class="st">"evalday"</span>, <span class="st">"posaff"</span>,<span class="st">"negaff"</span>,<span class="st">"temp"</span>,<span class="st">"hum"</span>,<span class="st">"wind"</span>,<span class="st">"bar"</span>,<span class="st">"prec"</span>)]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">#removing observations with NA</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>dailysub <span class="ot">&lt;-</span> daily[<span class="fu">complete.cases</span>(daily), ] </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="fu">describe</span>(dailysub)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        vars    n    mean      sd  median trimmed     mad     min     max
id         1 1376 3276.28 1279.88 3271.50 3302.24 1497.43 1010.00 5327.00
slphrs     2 1376    7.20    1.81    7.00    7.20    1.48    0.00   18.00
weath      3 1376    2.00    1.29    2.00    2.00    1.48    0.00    4.00
lteq       4 1376   12.50   10.42    9.00   11.24    8.90    0.00   58.00
pss        5 1376    2.62    0.68    2.75    2.64    0.74    0.00    4.00
se         6 1376    3.43    0.99    3.00    3.46    1.48    1.00    5.00
swls       7 1376    4.11    1.27    4.20    4.15    1.19    1.00    7.00
evalday    8 1376    0.68    0.46    1.00    0.73    0.00    0.00    1.00
posaff     9 1376    4.11    1.10    4.20    4.14    1.19    1.00    7.00
negaff    10 1376    2.45    1.04    2.20    2.34    1.04    1.00    6.90
temp      11 1376   40.18    7.88   42.00   40.51    8.90   20.80   56.00
hum       12 1376    0.62    0.20    0.66    0.63    0.21    0.24    0.90
wind      13 1376    7.36    4.45    7.00    6.81    4.45    0.70   20.00
bar       14 1376   30.02    0.33   30.00   30.04    0.43   29.32   30.54
prec      15 1376    0.05    0.09    0.00    0.03    0.00    0.00    0.30
          range  skew kurtosis    se
id      4317.00 -0.10    -1.04 34.50
slphrs    18.00  0.12     1.93  0.05
weath      4.00 -0.06    -1.06  0.03
lteq      58.00  1.07     0.95  0.28
pss        4.00 -0.37     0.17  0.02
se         4.00 -0.40    -0.12  0.03
swls       6.00 -0.28    -0.22  0.03
evalday    1.00 -0.79    -1.37  0.01
posaff     6.00 -0.24    -0.37  0.03
negaff     5.90  0.95     0.67  0.03
temp      35.20 -0.37    -0.24  0.21
hum        0.66 -0.36    -1.10  0.01
wind      19.30  0.97     0.86  0.12
bar        1.22 -0.39    -0.90  0.01
prec       0.30  1.85     1.98  0.00</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#scaling all the variables</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>dailyscale <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">scale</span>(dailysub, <span class="at">center=</span><span class="cn">TRUE</span>, <span class="at">scale=</span><span class="cn">TRUE</span>))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">#checking and fixing the id variable (which we did not want standardized)</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(dailyscale<span class="sc">$</span>id)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:1376] -1.77 -1.77 -1.77 -1.77 -1.77 ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>dailyscale<span class="sc">$</span>id <span class="ot">&lt;-</span> dailysub<span class="sc">$</span>id</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(dailyscale<span class="sc">$</span>id)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:1376] 1010 1011 1012 1013 1014 ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">describe</span>(dailyscale)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        vars    n    mean      sd  median trimmed     mad     min     max
id         1 1376 3276.28 1279.88 3271.50 3302.24 1497.43 1010.00 5327.00
slphrs     2 1376    0.00    1.00   -0.11    0.00    0.82   -3.98    5.98
weath      3 1376    0.00    1.00    0.00    0.00    1.15   -1.55    1.54
lteq       4 1376    0.00    1.00   -0.34   -0.12    0.85   -1.20    4.37
pss        5 1376    0.00    1.00    0.19    0.03    1.08   -3.83    2.02
se         6 1376    0.00    1.00   -0.43    0.04    1.49   -2.45    1.58
swls       7 1376    0.00    1.00    0.07    0.03    0.93   -2.45    2.27
evalday    8 1376    0.00    1.00    0.68    0.10    0.00   -1.47    0.68
posaff     9 1376    0.00    1.00    0.08    0.03    1.08   -2.82    2.63
negaff    10 1376    0.00    1.00   -0.24   -0.11    1.00   -1.40    4.28
temp      11 1376    0.00    1.00    0.23    0.04    1.13   -2.46    2.01
hum       12 1376    0.00    1.00    0.20    0.05    1.06   -1.94    1.42
wind      13 1376    0.00    1.00   -0.08   -0.12    1.00   -1.50    2.84
bar       14 1376    0.00    1.00   -0.05    0.06    1.29   -2.09    1.56
prec      15 1376    0.00    1.00   -0.53   -0.26    0.00   -0.53    2.68
          range  skew kurtosis    se
id      4317.00 -0.10    -1.04 34.50
slphrs     9.97  0.12     1.93  0.03
weath      3.09 -0.06    -1.06  0.03
lteq       5.57  1.07     0.95  0.03
pss        5.85 -0.37     0.17  0.03
se         4.03 -0.40    -0.12  0.03
swls       4.72 -0.28    -0.22  0.03
evalday    2.15 -0.79    -1.37  0.03
posaff     5.45 -0.24    -0.37  0.03
negaff     5.68  0.95     0.67  0.03
temp       4.47 -0.37    -0.24  0.03
hum        3.36 -0.36    -1.10  0.03
wind       4.33  0.97     0.86  0.03
bar        3.65 -0.39    -0.90  0.03
prec       3.21  1.85     1.98  0.03</code></pre>
</div>
</div>
<section id="k-means" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="k-means">K-Means</h2>
</section>
<p>Basic clustering in the social sciences often makes use of the <em>K-means</em> procedure.</p>
<p>The k-means algorithm is a traditional and widely used clustering algorithm.</p>
<p>In brief, the algorithm begins by specifying the number of clusters we are interested in. This is the <em>k</em>. Each of the <em>k</em> clusters is identified by the vector of the average (i.e., the mean) value of each of the variables for observations within a cluster. A random clustering is constructed (random set of mean vectors).</p>
<p>The <em>k</em> means are calculated. Then, using the distance measure, we gravitate each observation to its nearest mean. The means are then recalculated and the points re-gravitate. And so on until there is no further change to the means.</p>
<p>Let’s see an example where we chose <span class="math inline">\(K=4\)</span>.</p>
<p>We use the R function <code>kmeans()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#there are random starts involved so we set a seed</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">#running a cluster analysis</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(dailyscale[,<span class="fu">c</span>(<span class="st">"lteq"</span>,<span class="st">"posaff"</span>)], <span class="at">centers=</span><span class="dv">4</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>K-means clustering with 4 clusters of sizes 377, 578, 240, 181

Cluster means:
        lteq     posaff
1 -0.6558537 -1.0705106
2 -0.4408363  0.6996343
3  0.7763740 -0.5678819
4  1.7443674  0.7485388

Clustering vector:
   1    2    3    4    5    6    7    9   10   11   13   14   15   17   18   19 
   2    1    2    2    3    3    4    2    4    2    2    2    1    2    2    2 
  20   21   22   23   27   28   29   30   31   32   37   38   39   40   41   42 
   1    1    1    4    1    1    1    1    2    2    2    2    2    2    1    2 
  43   44   47   48   49   51   52   53   54   55   56   57   58   59   60   61 
   2    1    2    2    2    2    2    2    2    1    3    3    1    1    1    3 
  62   63   64   66   67   68   70   71   72   73   74   75   76   77   78   79 
   3    2    4    3    1    3    2    2    2    2    2    2    2    1    2    3 
  81   84   85   86   87   88   89   90   91   92   93   95   96   97   98   99 
   2    1    3    1    2    2    2    4    4    4    4    2    2    2    2    4 
 101  102  103  105  106  107  108  110  111  112  113  114  115  116  117  118 
   4    3    2    3    4    4    3    2    4    4    4    4    4    2    4    4 
 119  120  121  122  123  124  125  126  127  128  129  130  131  132  133  134 
   4    3    1    1    1    1    1    1    1    2    2    2    2    2    2    2 
 135  136  137  138  140  141  143  144  145  146  147  149  150  151  152  153 
   2    4    4    2    3    3    3    4    3    4    4    4    4    4    1    3 
 154  155  156  157  158  159  160  161  162  163  164  165  166  167  168  169 
   2    3    2    3    3    2    2    2    2    2    2    2    2    2    2    2 
 170  171  172  173  174  175  176  177  178  179  180  181  182  183  184  185 
   1    2    3    1    1    1    1    1    1    1    1    2    2    2    3    3 
 186  187  188  189  190  191  192  193  194  196  197  198  199  201  202  203 
   2    4    4    4    3    3    4    1    1    2    2    2    2    2    4    4 
 204  205  206  208  209  210  211  212  213  214  215  216  217  218  219  220 
   2    2    4    4    4    2    2    2    2    2    2    1    2    3    3    1 
 221  222  223  224  225  226  228  229  230  231  232  233  234  235  236  237 
   1    3    3    3    3    2    2    2    1    1    2    3    3    2    3    1 
 238  239  240  241  242  243  244  245  246  247  248  249  250  251  252  253 
   2    2    1    1    3    3    2    3    3    2    3    2    3    3    3    3 
 254  255  256  257  258  259  260  261  262  263  264  265  266  267  268  269 
   3    4    3    3    2    2    2    2    1    2    2    2    2    1    2    1 
 270  271  272  273  274  275  276  277  278  279  280  281  282  283  285  286 
   3    3    2    2    2    2    1    1    1    2    1    1    1    3    3    1 
 287  288  289  290  291  292  293  294  295  296  297  298  299  300  301  302 
   1    2    2    1    1    1    1    1    1    2    2    2    3    1    2    1 
 303  304  305  306  307  308  309  312  313  314  315  316  317  318  319  320 
   3    2    2    2    2    2    1    2    2    2    2    3    3    1    1    2 
 321  323  324  325  326  327  328  329  330  331  332  333  334  335  343  344 
   2    2    2    2    2    2    2    4    2    2    2    2    2    2    3    2 
 345  346  347  348  349  350  352  353  354  355  356  358  359  360  361  364 
   1    2    1    2    2    2    2    2    2    1    1    1    1    2    4    4 
 365  366  367  368  369  370  371  372  373  374  376  377  378  379  380  381 
   4    4    2    2    2    2    3    2    2    3    1    1    1    2    2    1 
 382  383  384  385  386  387  388  389  390  391  392  393  394  395  396  397 
   1    2    3    2    3    2    2    3    3    3    3    4    1    1    4    3 
 398  399  400  401  402  403  404  405  406  407  408  409  410  411  412  413 
   4    4    4    1    1    4    4    3    4    1    1    1    2    1    1    1 
 414  415  416  417  418  419  422  423  424  425  426  427  428  429  430  431 
   1    2    2    2    2    2    1    2    3    3    4    3    3    4    4    2 
 432  433  434  435  436  437  438  439  441  442  443  444  445  446  447  448 
   2    2    2    2    3    1    1    3    2    2    3    3    3    3    2    2 
 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 
   2    2    2    2    2    2    1    1    1    1    3    3    1    3    2    2 
 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 
   1    1    2    2    2    1    2    2    3    3    2    1    1    1    1    1 
 481  483  485  486  487  488  489  490  491  492  493  494  495  496  497  498 
   2    1    2    2    2    1    1    1    1    1    1    2    1    2    1    1 
 499  500  501  502  503  504  505  506  507  508  509  510  511  512  513  514 
   1    1    2    2    3    3    3    3    3    2    2    2    2    2    2    2 
 515  516  517  518  519  520  521  522  523  524  525  526  527  528  529  530 
   1    1    4    3    2    2    4    2    4    4    1    1    1    2    3    3 
 531  533  534  535  536  537  538  539  540  541  542  543  544  545  546  548 
   3    3    4    4    4    1    1    1    1    1    1    1    4    4    2    4 
 549  550  551  552  553  554  555  556  557  558  559  560  561  562  563  564 
   4    2    2    2    4    3    3    4    1    3    4    2    3    1    1    2 
 565  566  567  568  569  570  571  572  573  574  575  576  577  578  579  580 
   3    1    1    2    2    2    2    2    2    2    2    1    3    4    4    4 
 581  582  583  584  585  586  587  588  589  590  591  592  593  594  595  596 
   3    1    1    1    2    2    1    1    2    1    1    2    1    1    1    2 
 597  598  599  601  602  603  604  605  606  607  609  610  611  612  613  614 
   1    1    1    2    1    1    2    1    1    1    2    2    2    2    1    1 
 615  616  617  618  619  620  621  622  623  624  625  626  628  629  630  631 
   2    2    2    3    2    2    3    1    1    2    2    2    2    2    2    2 
 632  633  634  635  636  637  638  639  640  641  642  643  644  645  646  647 
   1    1    1    3    1    2    1    1    2    3    2    3    1    1    1    1 
 648  649  650  651  652  653  654  655  656  657  658  659  660  661  662  663 
   1    2    3    1    1    1    3    4    3    1    1    1    1    1    1    3 
 664  665  666  667  668  669  670  671  672  673  674  675  676  677  678  679 
   3    4    4    4    4    4    4    3    4    4    4    2    2    1    4    2 
 680  681  682  684  685  686  687  688  689  690  691  692  693  694  696  697 
   2    2    2    1    3    2    2    4    4    2    2    2    4    4    2    1 
 698  699  700  701  702  703  704  705  706  707  708  709  710  711  712  713 
   1    2    1    1    1    3    3    3    3    3    3    1    3    1    1    1 
 714  715  716  717  719  720  721  722  723  724  725  726  727  728  731  735 
   2    1    1    1    1    1    3    1    1    1    1    3    4    4    4    2 
 736  737  738  739  740  741  742  743  744  745  746  747  748  749  750  751 
   4    2    4    4    3    3    3    4    3    3    2    4    3    3    2    2 
 752  753  754  755  757  758  759  760  761  762  763  764  765  766  767  768 
   3    3    2    2    1    2    2    1    1    2    2    1    2    2    2    2 
 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 
   2    1    2    2    3    1    3    3    3    1    1    1    3    1    1    1 
 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 
   1    1    1    1    2    2    1    1    4    4    4    1    3    2    4    4 
 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 
   4    4    4    1    3    1    2    2    2    2    2    2    2    1    1    1 
 817  819  820  821  822  823  824  825  826  827  828  829  830  831  832  833 
   2    1    1    1    1    2    2    2    1    2    1    4    1    1    2    2 
 834  835  836  837  838  839  840  841  842  843  844  845  846  847  848  849 
   1    4    1    2    2    2    1    2    2    2    3    3    3    1    3    2 
 850  851  852  853  854  855  856  857  858  859  860  861  862  863  864  866 
   2    1    2    1    3    2    2    4    4    2    4    2    4    4    3    4 
 867  868  869  871  872  873  874  875  876  877  878  879  880  881  882  883 
   3    4    4    3    4    3    4    1    1    4    1    1    2    1    2    1 
 884  885  886  887  888  889  890  891  892  893  894  895  896  897  898  899 
   1    2    2    1    1    1    2    1    2    2    3    3    2    2    1    2 
 900  901  902  903  904  905  906  907  908  909  910  911  912  913  914  915 
   2    2    2    2    2    1    3    1    2    2    3    3    3    1    3    3 
 916  917  918  919  920  921  922  923  924  925  926  927  928  929  930  931 
   3    3    2    3    2    3    2    1    2    1    2    2    1    2    2    2 
 932  933  934  935  936  937  938  940  942  943  944  945  946  947  948  949 
   1    2    4    4    4    4    4    2    2    2    2    2    1    3    2    2 
 950  951  952  953  956  957  958  959  960  961  962  963  964  965  966  967 
   3    3    2    1    1    1    2    2    2    3    3    3    3    2    3    3 
 968  969  970  971  972  973  974  976  977  978  979  980  982  983  984  985 
   2    1    1    3    4    3    1    2    2    3    3    3    2    2    2    2 
 986  987  988  989  990  991  992  993  994  995  996  997  998  999 1000 1001 
   1    3    3    1    3    3    2    2    4    3    3    3    1    2    3    1 
1002 1003 1004 1005 1006 1007 1008 1009 1011 1012 1013 1014 1015 1016 1017 1018 
   3    4    3    4    1    2    2    2    1    1    2    3    3    3    4    4 
1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 
   2    2    2    1    3    3    3    4    4    1    2    1    3    1    1    1 
1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 
   1    1    1    2    2    2    2    2    2    2    2    4    2    2    2    2 
1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1064 1065 1066 1067 
   4    2    4    2    2    2    2    1    1    1    1    3    3    1    3    2 
1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 
   2    3    2    4    2    3    3    3    4    2    2    2    2    1    2    1 
1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 
   3    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 
   2    2    1    2    1    1    2    1    2    2    4    2    4    2    2    2 
1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 
   2    2    2    3    3    3    1    3    2    2    2    2    2    2    4    4 
1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 
   4    2    2    4    2    4    4    3    4    4    2    2    2    3    2    2 
1148 1149 1150 1151 1152 1153 1154 1156 1157 1158 1160 1161 1162 1163 1164 1165 
   2    2    2    2    1    2    2    1    2    1    2    2    2    1    1    1 
1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 
   2    4    4    1    3    1    4    2    4    3    3    2    3    3    4    4 
1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 
   1    2    2    1    2    2    3    1    3    3    4    2    2    4    2    4 
1198 1199 1200 1201 1202 1203 1204 1205 1207 1208 1209 1210 1211 1212 1213 1215 
   2    2    2    2    2    2    1    1    2    1    2    2    2    2    2    2 
1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 
   2    1    2    2    2    2    1    2    1    2    2    1    2    1    4    4 
1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 
   4    3    4    4    3    3    2    2    1    2    2    2    1    1    2    2 
1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 
   2    3    1    2    4    2    4    4    2    4    4    4    3    4    2    2 
1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 
   2    2    3    2    1    3    2    3    4    4    1    2    2    4    2    2 
1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 
   2    2    1    1    1    1    2    1    1    1    2    2    2    2    2    2 
1296 1297 1298 1299 1300 1301 1302 1304 1305 1306 1307 1308 1309 1310 1311 1312 
   3    1    3    2    2    2    2    1    1    1    1    2    2    2    2    2 
1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 
   2    2    2    2    1    2    2    2    2    1    2    2    2    1    2    1 
1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 
   1    1    1    4    1    3    2    3    3    3    3    2    2    2    2    2 
1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 
   1    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 
   2    2    2    2    2    2    2    2    1    2    2    4    4    3    1    4 
1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 
   3    3    3    4    1    2    2    4    4    4    4    1    1    1    1    1 
1393 1394 1395 1396 1397 1398 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 
   1    1    1    3    3    3    2    3    3    4    1    1    2    2    1    2 
1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 
   3    2    1    2    2    1    1    1    1    2    1    2    1    1    1    1 
1426 1427 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 
   1    2    4    4    4    3    1    3    4    3    1    1    1    1    1    1 
1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 
   2    1    1    1    1    1    1    1    3    1    2    2    1    3    2    2 

Within cluster sum of squares by cluster:
[1] 201.2980 329.1644 175.7229 180.1350
 (between_SS / total_SS =  67.8 %)

Available components:

[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
[6] "betweenss"    "size"         "iter"         "ifault"      </code></pre>
</div>
</div>
<p>That is a lot of output! - but pretty easy to walk through and understand. The algorithm even gives a within cluster sum of squares, which is a measure of the explained variance.</p>
<p>Let’s extract the mean vectors and plot for a more intuitive understanding of the results.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#getting centers</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>centers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        lteq     posaff
1 -0.6558537 -1.0705106
2 -0.4408363  0.6996343
3  0.7763740 -0.5678819
4  1.7443674  0.7485388</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plotting clustered data points with k means</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dailyscale,<span class="fu">aes</span>(<span class="at">x=</span>lteq,<span class="at">y=</span>posaff)) <span class="sc">+</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span>model<span class="sc">$</span>cluster, <span class="at">alpha=</span>.<span class="dv">6</span>) <span class="sc">+</span><span class="co">#plotting all the points</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">#plotting the centroids</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>model<span class="sc">$</span>centers[<span class="dv">1</span>,<span class="dv">1</span>],<span class="at">y=</span>model<span class="sc">$</span>centers[<span class="dv">1</span>,<span class="dv">2</span>]),<span class="at">color=</span><span class="dv">1</span>,<span class="at">size=</span><span class="dv">5</span>,<span class="at">shape=</span><span class="dv">18</span>) <span class="sc">+</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>model<span class="sc">$</span>centers[<span class="dv">2</span>,<span class="dv">1</span>],<span class="at">y=</span>model<span class="sc">$</span>centers[<span class="dv">2</span>,<span class="dv">2</span>]),<span class="at">color=</span><span class="dv">2</span>,<span class="at">size=</span><span class="dv">5</span>,<span class="at">shape=</span><span class="dv">18</span>) <span class="sc">+</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>model<span class="sc">$</span>centers[<span class="dv">3</span>,<span class="dv">1</span>],<span class="at">y=</span>model<span class="sc">$</span>centers[<span class="dv">3</span>,<span class="dv">2</span>]),<span class="at">color=</span><span class="dv">3</span>,<span class="at">size=</span><span class="dv">5</span>,<span class="at">shape=</span><span class="dv">18</span>) <span class="sc">+</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>model<span class="sc">$</span>centers[<span class="dv">4</span>,<span class="dv">1</span>],<span class="at">y=</span>model<span class="sc">$</span>centers[<span class="dv">4</span>,<span class="dv">2</span>]),<span class="at">color=</span><span class="dv">4</span>,<span class="at">size=</span><span class="dv">5</span>,<span class="at">shape=</span><span class="dv">18</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week6_3_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<section id="evaluation-of-clustering-quality" class="level3" style="color: lighyellow">
<h3 class="anchored" data-anchor-id="evaluation-of-clustering-quality">Evaluation of Clustering Quality</h3>
</section>
<p>Numerous measures are available for evaluating a clustering. Many are stored within the model object returned by <code>kmeans()</code>.</p>
<p>A basic concept for evaluating the quality of the clusters is the <em>sum of squares</em>. This is typically a sum of the square of the distances between observations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>totss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2750</code></pre>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 201.2980 329.1644 175.7229 180.1350</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>tot.withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 886.3203</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>betweenss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1863.68</code></pre>
</div>
</div>
<p>Evaluation of the sum of squares can help us both evaluate the quality of any given solution, as well as help us choose the number of clusters, <em>k</em>, needed to describe the data.</p>
<p><strong>Evaluation: Within Sum of Squares</strong></p>
<p>The within sum of squares is a measure of how <em>close</em> the observations are within the clusters. For a single cluster this is calculated as the average squared distance of each observation within the cluster from the cluster mean. Then the total within sum of squares is the sum of the within sum of squares over all clusters.</p>
<p>The total within sum of squares generally decreases as the number of clusters increases. As we increase the number of clusters they individually tend to become smaller and the observations closer together within the clusters. As <em>k</em> increases, the changes in the total within sum of squares would be expected to reduce, and so it flattens out. A good value of <em>k</em> might be where the reduction in the total weighted sum of squares begins to flatten.</p>
<p>General rule of thumb: Aim to minimize the total within sum of squares (achieve within-group similarity).</p>
<p><strong>Evaluation: Between Sum of Squares</strong></p>
<p>The between sum or squares is a measure of how <em>far</em> the clusters are from each other.</p>
<p>General rule of thumb: Aim to maximize the between sum of squares (achieve between-group dissimilarity).</p>
<p>A good clustering will have a small within sum of squares and a large between sum of squares.</p>
<p>So, we need to have a range of solutions to see how the within and between sum of squares looks with different <em>k</em>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#making a empty dataframe</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>criteria <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co">#setting range of k                   </span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>nk <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co">#loop for range of clusters</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> nk) {</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(dailyscale[,<span class="fu">c</span>(<span class="st">"lteq"</span>,<span class="st">"posaff"</span>)], k)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>criteria <span class="ot">&lt;-</span> <span class="fu">rbind</span>(criteria,<span class="fu">c</span>(k,model<span class="sc">$</span>tot.withinss,model<span class="sc">$</span>betweenss,model<span class="sc">$</span>totss))</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co">#renaming columns</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(criteria) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"k"</span>,<span class="st">"tot.withinss"</span>,<span class="st">"betweenss"</span>,<span class="st">"totalss"</span>)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">#scree plot</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(criteria, <span class="fu">aes</span>(<span class="at">x=</span>k)) <span class="sc">+</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y=</span>tot.withinss),<span class="at">color=</span><span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>tot.withinss),<span class="at">color=</span><span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y=</span>betweenss),<span class="at">color=</span><span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>betweenss),<span class="at">color=</span><span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"k = number of clusters"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Sum of Squares (within = red, between = blue)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week6_3_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">#looking at criteria</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(criteria,<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    k tot.withinss betweenss totalss
1   1      2750.00      0.00    2750
2   2      1786.49    963.51    2750
3   3      1082.70   1667.30    2750
4   4       877.93   1872.07    2750
5   5       729.55   2020.45    2750
6   6       584.64   2165.36    2750
7   7       498.26   2251.74    2750
8   8       445.17   2304.83    2750
9   9       396.60   2353.40    2750
10 10       360.53   2389.47    2750
11 11       326.35   2423.65    2750
12 12       306.13   2443.87    2750
13 13       288.76   2461.24    2750
14 14       261.78   2488.22    2750
15 15       262.64   2487.36    2750
16 16       232.66   2517.34    2750
17 17       216.25   2533.75    2750
18 18       207.83   2542.17    2750
19 19       195.18   2554.82    2750
20 20       188.38   2561.62    2750</code></pre>
</div>
</div>
<p>From the scree plot, we might look for 6 clusters (but it is really hard to see any “elbow”).</p>
<p>There are also additional quantitative criteria that can be used to inform selection.</p>
<p>For example, the Calinski-Harabasz criterion, also known as the variance ratio criterion, is the ratio of the between sum of squares (divided by k - 1) to the within sum of squares (divided by n - k).</p>
<p>The relative values can be used to compare clusterings of a single dataset, with higher values being better clusterings. The criterion is said to work best for spherical clusters with compact centers (as with normally distributed data) using k-means with Euclidean distance.</p>
<p>And of course this is a well-trodden area of research so there are many criteria - and packages that calculate them for you - and make automated choices.</p>
<p>Don’t just pick an index that shows your solution but check out the next point that talks about the stability of the solution. There is not “standard reporting” of cluster analysis results in the psychological literature. Different authors report different things - but all are using some metrics to justify the choice of <em>k</em>, and to support why the chosen cluster solution is a good description of the data.</p>
<section id="obtaining-a-stable-solution" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="obtaining-a-stable-solution">Obtaining a Stable Solution</h2>
</section>
<p>Recall that k-means begins the iterations with a random cluster assignment. Different starting points may lead to different solutions. So, it may be useful to start many times to locate a stable solution. This is automated within the <code>kmeans()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">#kmeans with nstart = 1</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>km.res <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(dailyscale[,<span class="fu">c</span>(<span class="st">"lteq"</span>,<span class="st">"posaff"</span>)], <span class="at">centers=</span><span class="dv">4</span>, <span class="at">nstart =</span> <span class="dv">1</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>km.res<span class="sc">$</span>tot.withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 892.5106</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">#kmeans with nstart = 25</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>km.res <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(dailyscale[,<span class="fu">c</span>(<span class="st">"lteq"</span>,<span class="st">"posaff"</span>)], <span class="at">centers=</span><span class="dv">4</span>, <span class="at">nstart =</span> <span class="dv">25</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>km.res<span class="sc">$</span>tot.withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 877.9312</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">#kmeans with nstart = 50</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>km.res <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(dailyscale[,<span class="fu">c</span>(<span class="st">"lteq"</span>,<span class="st">"posaff"</span>)], <span class="at">centers=</span><span class="dv">4</span>, <span class="at">nstart =</span> <span class="dv">50</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>km.res<span class="sc">$</span>tot.withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 877.9312</code></pre>
</div>
</div>
<p>The improvement can be seen over the single random start.</p>
<p>Recommended to do 25+ or 50 for stable solutions.</p>
<p><strong>Replication</strong></p>
<p>It may also be informative to repeat the procedure on randomly selected portions of the sample. If the cluster solution replicates in (random) subsets of the data - that would be strong evidence that the typology is pervasive and meaningful.</p>
<section id="post-clustering-analyses" class="level1" style="color: yellow">
<h1>Post-Clustering Analyses</h1>
</section>
<p>After finding a suitable cluster solution, each individual is placed in a cluster. Formally, we obtain a vector of cluster assignments - a new categorical, grouping variable.</p>
<p>What’s next?</p>
<p>Well, we can both describe the clusters and use this new cluster variable in some other analysis - ANOVAs to test group differences, Chi-square tests, Multinomial regressions … the cluster variable can be used as a predictor, a correlate, an outcome (e.g., check whether those clusters are for example differ across personality variables etc.)</p>
<section id="describing-clusters" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="describing-clusters">Describing Clusters</h2>
</section>
<p>First we merge the vector of cluster assignments back into the data set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>dailyscale.clus <span class="ot">&lt;-</span> <span class="fu">cbind</span>(km.res<span class="sc">$</span>cluster,dailyscale)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(dailyscale.clus)[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="st">"cluster"</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dailyscale.clus[,<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="dv">6</span>)],<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  cluster   id     slphrs         weath        pss
1       2 1010 -0.6623479 -0.7732500468 -0.1732048
2       2 1011 -2.8774184 -0.0005615469  0.1923317
3       3 1012  0.9989549  0.7721269531  1.2889411
4       3 1013  0.1683035 -0.0005615469  0.5578682</code></pre>
</div>
</div>
<p>We can describe the different clusters - and potentially name the clusters.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Gather the data to 'long' format so the clustering variables are all in one column</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co">#gather() has been replaced by pivot_longer()</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>longdata <span class="ot">&lt;-</span> dailyscale.clus <span class="sc">%&gt;%</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">c</span>(lteq, posaff), <span class="at">names_to =</span> <span class="st">"variable"</span>, <span class="at">values_to =</span> <span class="st">"value"</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the summary statistics seperately for cluster and variable (i.e. lteq, posaff)</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>summary <span class="ot">&lt;-</span> longdata <span class="sc">%&gt;%</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>             <span class="fu">group_by</span>(cluster, variable) <span class="sc">%&gt;%</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>             <span class="fu">summarise</span>(<span class="at">mean =</span> <span class="fu">mean</span>(value), <span class="at">se =</span> <span class="fu">sd</span>(value) <span class="sc">/</span> <span class="fu">length</span>(value))</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(summary, <span class="fu">aes</span>(<span class="at">x =</span> variable, <span class="at">y =</span> mean, <span class="at">fill =</span> variable)) <span class="sc">+</span> </span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">'identity'</span>, <span class="at">position =</span> <span class="st">'dodge'</span>) <span class="sc">+</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> mean <span class="sc">-</span> se, <span class="at">ymax =</span> mean <span class="sc">+</span> se),                            </span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>                  <span class="at">width =</span> <span class="fl">0.2</span>,</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>                  <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="fl">0.9</span>)) <span class="sc">+</span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>cluster) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week6_3_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>From this plot we can see the multivariate “profile” of each cluster - and use that to name the clusters. There can be some label switching, depending on random starting values, in terms of the cluster membership identifiers.</p>
<p>There are 4 profiles:</p>
<ul>
<li><p>Vigorous Exercisers</p></li>
<li><p>Happy Sedentary</p></li>
<li><p>Happy Exercisers</p></li>
<li><p>Unhappy Sedentary</p></li>
</ul>
<section id="analyzing-clusters" class="level2" style="color: orange">
<h2 class="anchored" data-anchor-id="analyzing-clusters">Analyzing Clusters</h2>
</section>
<p>Now that we have clusters = groups, we can analyze them. For example, we can take our 4-cluster solution and see if the clusters differ on another variable.</p>
<p>Let’s see how the cluster groups differ on perceived stress (<code>pss</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">aov</span>(pss <span class="sc">~</span> <span class="fu">factor</span>(km.res<span class="sc">$</span>cluster), <span class="at">data=</span>dailyscale.clus)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                         Df Sum Sq Mean Sq F value Pr(&gt;F)    
factor(km.res$cluster)    3    247   82.35   100.2 &lt;2e-16 ***
Residuals              1372   1128    0.82                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">TukeyHSD</span>(fit1) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = pss ~ factor(km.res$cluster), data = dailyscale.clus)

$`factor(km.res$cluster)`
            diff        lwr        upr     p adj
2-1 -0.443865711 -0.6488720 -0.2388594 0.0000002
3-1  0.486036094  0.2765007  0.6955715 0.0000000
4-1  0.493702753  0.2813826  0.7060229 0.0000000
3-2  0.929901806  0.7681609  1.0916427 0.0000000
4-2  0.937568465  0.7722358  1.1029011 0.0000000
4-3  0.007666659 -0.1632497  0.1785830 0.9994508</code></pre>
</div>
</div>
<p>We see that clusters differ from each other on <code>pss</code>, except clusters 3 and 4 (or 3 and 2 if there was label switching).</p>
<p>Differences on <strong>non-clustering</strong> variables provide evidence that, indeed, the cluster solution is providing a meaningful distinction. The typology has value.</p>
<p>In sum, there are variety of ways to justify a cluster solution (e.g., selection of <em>k</em>)</p>
<ol type="1">
<li>Conceptual arguments</li>
<li>Internal statistical criteria</li>
<li>replication of clusters in random halves</li>
<li>cluster differentiation on external variables</li>
</ol>
<p>A practical benefit of subgroup-oriented interpretation emerges when considering potential interventions. Multivariate profiles may point toward tailoring diagnostic and intervention efforts to individual needs.</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>